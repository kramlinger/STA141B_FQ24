{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "405f2ffb",
   "metadata": {},
   "source": [
    "## Discussion Week 7: PageRank algorithm\n",
    "\n",
    "The goal this week to understand the [PageRank algorithm](https://en.wikipedia.org/wiki/PageRank#:~:text=PageRank%20(PR)%20is%20an%20algorithm,the%20importance%20of%20website%20pages.) for HW 4.\n",
    "\n",
    "### Problem description\n",
    "\n",
    "- Think of a hyperlinked set of documents. Wikepedia is a good example.\n",
    "- PageRank score: What is the probability that an internet surfer arrives at each document?\n",
    "- Surfing rules:\n",
    "    - The surfer starts at any document chosen at random.\n",
    "    - The surfer can either move to the linked document with probability $d$, or jump to any random document (without following the link) with probability $1-d$. The probability $d$ is called a *damping factor*. \n",
    "    - The surfer moves to the next document that is linked to the current document.\n",
    "    - If the current document has no link to other documents (this is called a *dangling node*), then the surfers moves to any document at random. (In other words, document with no outbound link is considered a document with outbound to all documents.)\n",
    "- PageRank calculation rules:\n",
    "    - PageRank is transferred from a given document to its outbound documents, divided equally among all outbound links.\n",
    "    \n",
    "**Remarks**\n",
    "- Link-to-everything for dangling nodes: Dangling nodes will only receive PageRank without transfering.\n",
    "- Damping factor: to allow traveling to all nodes (think of unconnected graphs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5e186",
   "metadata": {},
   "source": [
    "### Mathematical formulation\n",
    "\n",
    "- $N$: number of total documents\n",
    "- $p_i$: $i$th document, $i = 1, \\dots, N$\n",
    "- $M(p_i)$: set of documents that link to $p_i$ (dangling node adjusted)\n",
    "- $L(p_i)$: number of outbound links on $p_i$ (dangling node adjusted)\n",
    "\n",
    "\n",
    "Then the *PageRank score* of $p_i$ is defined as\n",
    "$$\n",
    "PR(p_i) = \\frac{1-d}{N} + d \\sum_{p_j \\in M(p_i)} \\frac{PR(p_j)}{L(p_j)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac314e2",
   "metadata": {},
   "source": [
    "#### Matrix notation\n",
    "\n",
    "- Adjacency matrix $A = [A_{ij}]$, $i,j = 1, \\dots, N$, $A_{ij} = 1$ if $p_j$ has a link to $p_i$\n",
    "- Scaled adjacency matrix $S = [S_{ij}]$, $i,j = 1, \\dots, N$, $S_{ij} = A_{ij} / \\sum_{i=1}^N A_{ij}$; scaled so that column sum is 1\n",
    "- Transition matrix $H$: Replace the 0-column in $S$ with $[1/N, 1/N, \\dots, 1/N]$. Formally,\n",
    "$$\n",
    "H_{ij} = \\begin{cases}\n",
    "S_{ij} & \\text{if } \\sum_{i=1}^N S_{ij} = 1 \\\\\n",
    "1/N & \\text{if } \\sum_{i=1}^N S_{ij} = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "- Google matrix $G$: With the damping factor $d$,\n",
    "$$\n",
    "G = dH + \\frac{1-d}{N} J,\n",
    "$$\n",
    "where $J = [J_{ij}]$ where $J_{ij} = 1$ for all $i, j = 1, \\dots, N$ (in other words, a $N\\times N$ matrix of 1).\n",
    "- Finally, the PageRank score vector $v$ is the solution of\n",
    "$$\n",
    "v = Gv.\n",
    "$$\n",
    "- In other words, $v$ is the 1st right eigenvector of $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2d762",
   "metadata": {},
   "source": [
    "**Construction of $G$**\n",
    "\\begin{align*}\n",
    "v_i &= \\frac{1-d}{N} + d \\sum_{j \\in M(i)} \\frac{v_j}{L(p_j)} \\\\\n",
    "&= \\frac{1-d}{N} + d v^\\top H_j, \\; H_j: j \\text{th column of } H\n",
    "\\end{align*}\n",
    "\n",
    "Stacking $v_i$, $i=1, \\dots, N$ into a column vector $v$,\n",
    "\\begin{align*}\n",
    "v &= \\frac{1-d}{N} \\mathbf{1}+ d Hv, \\; \\mathbf{1}: \\text{column vector of ones} = (1, 1, \\dots, 1)^\\top \\\\\n",
    "&= \\left( \\frac{1-d}{N} J+ d H \\right)v \\\\\n",
    "&= Gv\n",
    "\\end{align*}\n",
    "\n",
    "The second equality is because $J = \\mathbf{1} \\mathbf{1}^\\top$ and $\\mathbf{1}^\\top v = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a5602",
   "metadata": {},
   "source": [
    "**Remarks**\n",
    "- [More about the last point](https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem): The first eigenvalue is 1, and the elements of the corresponding eigenvector is positive.\n",
    "- Some people define adjacency matrix as the element being 1 when $p_i$ has a link to $p_j$. This is equivalent to considering the transpose of above matrices, and considering the left eigenvector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e9e84",
   "metadata": {},
   "source": [
    "### Calculation\n",
    "- [Power iteration](https://en.wikipedia.org/wiki/Power_iteration): Knowing that the corresponding eigenvalue is 1, the algorithm looks like:\n",
    "    1. Initialize $v^{(0)} = \\left( \\begin{matrix} 1/N \\\\ 1/N \\\\ \\vdots \\\\ 1/N \\end{matrix} \\right)$.\n",
    "    2. For $t = 0, 1, \\dots$, update $v^{(t+1)} = G v^{(t)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c9fc29",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "![A web with four documents.](graph.png)\n",
    "\n",
    "Please note that the codes below are not optimal and only shows a rough idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31bcdf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.33333333, 0.        ],\n",
       "       [0.5       , 0.        , 0.33333333, 0.        ],\n",
       "       [0.5       , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.33333333, 0.        ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "## Adjacency matrix\n",
    "# A = np.matrix([[0,0,1,0], [1,0,1,0], [1,0,0,0], [0,0,1,0]])\n",
    "N = 4\n",
    "row = np.array([1, 2, 0, 1, 3])\n",
    "col = np.array([0, 0, 2, 2, 2])\n",
    "data = np.array([1/2, 1/2, 1/3, 1/3, 1/3])\n",
    "A = csr_matrix((data, (row, col)), shape=(N, N)) # for sparse matrix\n",
    "A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd70c0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soobin.kim/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "L = A.sum(axis = 0) # column sum: number of outbounds from each node\n",
    "H = A\n",
    "H[:, np.where(L.A1 == 0)[0]] = 1/N # dangling adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5459cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.25      , 0.33333333, 0.25      ],\n",
       "       [0.5       , 0.25      , 0.33333333, 0.25      ],\n",
       "       [0.5       , 0.25      , 0.        , 0.25      ],\n",
       "       [0.        , 0.25      , 0.33333333, 0.25      ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be9385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.0375    , 0.25      , 0.32083333, 0.25      ],\n",
       "        [0.4625    , 0.25      , 0.32083333, 0.25      ],\n",
       "        [0.4625    , 0.25      , 0.0375    , 0.25      ],\n",
       "        [0.0375    , 0.25      , 0.32083333, 0.25      ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 0.85\n",
    "G = d*H + (1-d) / N * np.ones(N*N).reshape(N, N)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7cbf764",
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = np.array([1 / N] * N).reshape(4, 1)\n",
    "for _ in range(10):\n",
    "    v = G @ v0\n",
    "    v0 = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f1073ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.22048846],\n",
       "        [0.31419566],\n",
       "        [0.24482742],\n",
       "        [0.22048846]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1025bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.22048814],\n",
       "        [0.31419574],\n",
       "        [0.24482797],\n",
       "        [0.22048814]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43b080d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.22048822],\n",
       "        [0.31419572],\n",
       "        [0.24482783],\n",
       "        [0.22048822]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with...\n",
    "eee = np.linalg.eig(G)\n",
    "ev1 = eee[1][:,0] \n",
    "ev1 / sum(ev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d47d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way: uses sparse matrix H during calculation, \n",
    "## could be more efficient.\n",
    "v0 = np.array([1 / N] * N).reshape(4, 1)\n",
    "for _ in range(10):\n",
    "    v = d * H@v + (1-d) * np.mean(v0)\n",
    "    v0 = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c9fc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.22048822],\n",
       "        [0.31419572],\n",
       "        [0.24482783],\n",
       "        [0.22048822]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
