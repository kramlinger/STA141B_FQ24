{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff704263",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STA 141B Data & Web Technologies for Data Analysis\n",
    "\n",
    "### Lecture 6, 10/15/24, Concurrency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720fbd5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    " - Midterm this Thursday. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33924ccb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Last week's Topics\n",
    "\n",
    " - `numpy`\n",
    " - `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1204a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c9ad69d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading Data\n",
    "\n",
    "Pandas provides functions for reading (and writing) a variety of common formats. Most of their names begin with `read_`. For instance, we can read the dogs data from a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "68bcd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = pd.read_csv(\"../data/dogs_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c533e4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed</th>\n",
       "      <th>group</th>\n",
       "      <th>datadog</th>\n",
       "      <th>popularity_all</th>\n",
       "      <th>popularity</th>\n",
       "      <th>lifetime_cost</th>\n",
       "      <th>intelligence_rank</th>\n",
       "      <th>longevity</th>\n",
       "      <th>ailments</th>\n",
       "      <th>price</th>\n",
       "      <th>food_cost</th>\n",
       "      <th>grooming</th>\n",
       "      <th>kids</th>\n",
       "      <th>megarank_kids</th>\n",
       "      <th>megarank</th>\n",
       "      <th>size</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Border Collie</td>\n",
       "      <td>herding</td>\n",
       "      <td>3.64</td>\n",
       "      <td>45</td>\n",
       "      <td>39.0</td>\n",
       "      <td>20143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>weekly</td>\n",
       "      <td>low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Border Terrier</td>\n",
       "      <td>terrier</td>\n",
       "      <td>3.61</td>\n",
       "      <td>80</td>\n",
       "      <td>61.0</td>\n",
       "      <td>22638.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>weekly</td>\n",
       "      <td>high</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>small</td>\n",
       "      <td>13.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brittany</td>\n",
       "      <td>sporting</td>\n",
       "      <td>3.54</td>\n",
       "      <td>30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22589.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>weekly</td>\n",
       "      <td>medium</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cairn Terrier</td>\n",
       "      <td>terrier</td>\n",
       "      <td>3.53</td>\n",
       "      <td>59</td>\n",
       "      <td>48.0</td>\n",
       "      <td>21992.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.84</td>\n",
       "      <td>2.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>weekly</td>\n",
       "      <td>high</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>small</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Welsh Springer Spaniel</td>\n",
       "      <td>sporting</td>\n",
       "      <td>3.34</td>\n",
       "      <td>130</td>\n",
       "      <td>81.0</td>\n",
       "      <td>20224.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>weekly</td>\n",
       "      <td>high</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    breed     group  datadog  popularity_all  popularity  \\\n",
       "0           Border Collie   herding     3.64              45        39.0   \n",
       "1          Border Terrier   terrier     3.61              80        61.0   \n",
       "2                Brittany  sporting     3.54              30        30.0   \n",
       "3           Cairn Terrier   terrier     3.53              59        48.0   \n",
       "4  Welsh Springer Spaniel  sporting     3.34             130        81.0   \n",
       "\n",
       "   lifetime_cost  intelligence_rank  longevity  ailments  price  food_cost  \\\n",
       "0        20143.0                1.0      12.52       2.0  623.0      324.0   \n",
       "1        22638.0               30.0      14.00       0.0  833.0      324.0   \n",
       "2        22589.0               19.0      12.92       0.0  618.0      466.0   \n",
       "3        21992.0               35.0      13.84       2.0  435.0      324.0   \n",
       "4        20224.0               31.0      12.49       1.0  750.0      324.0   \n",
       "\n",
       "  grooming    kids  megarank_kids  megarank    size  weight  height  \n",
       "0   weekly     low            1.0      29.0  medium     NaN    20.0  \n",
       "1   weekly    high            2.0       1.0   small    13.5     NaN  \n",
       "2   weekly  medium            3.0      11.0  medium    35.0    19.0  \n",
       "3   weekly    high            4.0       2.0   small    14.0    10.0  \n",
       "4   weekly    high            5.0       4.0  medium     NaN    18.0  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca3756",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspecting Data\n",
    "\n",
    "Series and data frames provide many of the same methods and attributes as NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d327cf62",
   "metadata": {},
   "source": [
    "For a data frame, the `.dtypes` attribute gives the column types.\n",
    "\n",
    "The type \"object\" means some non-numeric Python object, often a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8be4e952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breed                 object\n",
       "group                 object\n",
       "datadog              float64\n",
       "popularity_all         int64\n",
       "popularity           float64\n",
       "lifetime_cost        float64\n",
       "intelligence_rank    float64\n",
       "longevity            float64\n",
       "ailments             float64\n",
       "price                float64\n",
       "food_cost            float64\n",
       "grooming              object\n",
       "kids                  object\n",
       "megarank_kids        float64\n",
       "megarank             float64\n",
       "size                  object\n",
       "weight               float64\n",
       "height               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b82c57",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are also several methods for quickly summarizing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1f10be24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datadog</th>\n",
       "      <th>popularity_all</th>\n",
       "      <th>popularity</th>\n",
       "      <th>lifetime_cost</th>\n",
       "      <th>intelligence_rank</th>\n",
       "      <th>longevity</th>\n",
       "      <th>ailments</th>\n",
       "      <th>price</th>\n",
       "      <th>food_cost</th>\n",
       "      <th>megarank_kids</th>\n",
       "      <th>megarank</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>86.00000</td>\n",
       "      <td>159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.603678</td>\n",
       "      <td>87.122093</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>19819.538462</td>\n",
       "      <td>40.924242</td>\n",
       "      <td>10.956741</td>\n",
       "      <td>1.216216</td>\n",
       "      <td>876.815068</td>\n",
       "      <td>489.597701</td>\n",
       "      <td>43.954023</td>\n",
       "      <td>43.942529</td>\n",
       "      <td>44.97093</td>\n",
       "      <td>19.089623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.570288</td>\n",
       "      <td>50.205335</td>\n",
       "      <td>25.258662</td>\n",
       "      <td>3102.475382</td>\n",
       "      <td>19.603560</td>\n",
       "      <td>1.995742</td>\n",
       "      <td>1.549810</td>\n",
       "      <td>461.172524</td>\n",
       "      <td>204.266894</td>\n",
       "      <td>25.288065</td>\n",
       "      <td>25.278153</td>\n",
       "      <td>35.52707</td>\n",
       "      <td>6.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12653.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.290000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.185000</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>17816.500000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>587.250000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>17.50000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.710000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>20087.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>11.290000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>795.000000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.035000</td>\n",
       "      <td>130.250000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>21798.000000</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>12.365000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1042.250000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>62.50000</td>\n",
       "      <td>24.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.640000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>26686.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3460.000000</td>\n",
       "      <td>1349.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>175.00000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         datadog  popularity_all  popularity  lifetime_cost  \\\n",
       "count  87.000000      172.000000   87.000000      91.000000   \n",
       "mean    2.603678       87.122093   44.000000   19819.538462   \n",
       "std     0.570288       50.205335   25.258662    3102.475382   \n",
       "min     0.990000        1.000000    1.000000   12653.000000   \n",
       "25%     2.185000       43.750000   22.500000   17816.500000   \n",
       "50%     2.710000       87.500000   44.000000   20087.000000   \n",
       "75%     3.035000      130.250000   65.500000   21798.000000   \n",
       "max     3.640000      173.000000   87.000000   26686.000000   \n",
       "\n",
       "       intelligence_rank   longevity    ailments        price    food_cost  \\\n",
       "count         132.000000  135.000000  148.000000   146.000000    87.000000   \n",
       "mean           40.924242   10.956741    1.216216   876.815068   489.597701   \n",
       "std            19.603560    1.995742    1.549810   461.172524   204.266894   \n",
       "min             1.000000    6.290000    0.000000   283.000000   270.000000   \n",
       "25%            27.000000    9.700000    0.000000   587.250000   324.000000   \n",
       "50%            42.000000   11.290000    1.000000   795.000000   466.000000   \n",
       "75%            54.250000   12.365000    2.000000  1042.250000   466.000000   \n",
       "max            80.000000   16.500000    9.000000  3460.000000  1349.000000   \n",
       "\n",
       "       megarank_kids   megarank     weight      height  \n",
       "count      87.000000  87.000000   86.00000  159.000000  \n",
       "mean       43.954023  43.942529   44.97093   19.089623  \n",
       "std        25.288065  25.278153   35.52707    6.012400  \n",
       "min         1.000000   1.000000    5.00000    5.000000  \n",
       "25%        22.500000  22.500000   17.50000   14.000000  \n",
       "50%        44.000000  44.000000   35.00000   19.000000  \n",
       "75%        65.500000  65.500000   62.50000   24.125000  \n",
       "max        87.000000  87.000000  175.00000   32.000000  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d84d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, get the string columns (`object`), then describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "38967214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breed</th>\n",
       "      <th>group</th>\n",
       "      <th>grooming</th>\n",
       "      <th>kids</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>172</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Border Collie</td>\n",
       "      <td>terrier</td>\n",
       "      <td>weekly</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>67</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                breed    group grooming  kids    size\n",
       "count             172      172      112   112     172\n",
       "unique            172        7        3     3       3\n",
       "top     Border Collie  terrier   weekly  high  medium\n",
       "freq                1       28       88    67      60"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs.select_dtypes(include = [\"object\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f6d6bdf4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>87.122093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>50.205335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>130.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>173.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       popularity_all\n",
       "count      172.000000\n",
       "mean        87.122093\n",
       "std         50.205335\n",
       "min          1.000000\n",
       "25%         43.750000\n",
       "50%         87.500000\n",
       "75%        130.250000\n",
       "max        173.000000"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs.select_dtypes(include = [\"int64\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622994e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aggregation\n",
    "\n",
    "Pandas also provides several methods for aggregating data, such as `.mean()`, `.median()`, `.std()`, and `.value_counts()`. They ignore missing values by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716f7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79f1df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dogs[\"price\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs[\"group\"].value_counts() # like R's table() with 1 arg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3ad1a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For counting one group against another (crosstabulating), use `pd.crosstab()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dogs[\"group\"], dogs[\"kids\"]) # like R's table() with 2+ arg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63b92e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applying Functions\n",
    "\n",
    "You can also use Pandas to apply your own aggregation functions to columns or rows.\n",
    "\n",
    "* `.apply()` applies a function column-by-column or row-by-row.\n",
    "* `.applymap()` applies a function element-by-element.\n",
    "\n",
    "This is another way to vectorizing code, but only works for DataFrame. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread(x):\n",
    "    '''Returns spread. Input is a single column (or row)'''\n",
    "    return x.max() - x.min()\n",
    "    \n",
    "dogs.select_dtypes(include = [\"float64\", \"int64\"]).apply(spread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc50033a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712150c8",
   "metadata": {},
   "source": [
    "Use the `.groupby()` method to group data before computing aggregate statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f922682",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878bd289",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dogs.groupby(\"group\").mean(numeric_only=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1db5a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By default, the groups become the index. You can keep them as regular columns by setting `as_index = False` when grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ddcedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.groupby(\"group\", as_index = False).mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50e784",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can group by multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.groupby([\"group\", \"kids\"]).mean(numeric_only=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c671dce",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On groups, the `.apply()` method computes group-by-group. It is the most general form of two other methods:\n",
    "\n",
    "* `.agg()`, which applies a function to each group to compute summary statistics\n",
    "* `.transform()`, which applies a function to each group to compute transformations (such as standardization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076d18e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tidying a Dataset\n",
    "\n",
    "Do Americans prefer low fat milk over whole milk?\n",
    "\n",
    "The USDA publishes data about dairy production. We can answer the question with the [Milk Sales Dataset](https://www.ers.usda.gov/webdocs/DataFiles/48685/fluidmilk.xlsx?v=5010.6).\n",
    "\n",
    "Many of Python's visualization packages expect [tidy data](https://vita.had.co.nz/papers/tidy-data.pdf), which means:\n",
    "\n",
    "1. Each feature must have its own column.\n",
    "2. Each observation must have its own row.\n",
    "3. Each value must have its own cell.\n",
    "\n",
    "Let's tidy up the Milk Sales Dataset so we can make a line plot that shows how milk sales have changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69313cb3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41102177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "milk = pd.read_excel(\"../data/fluidmilk.xlsx\")\n",
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea8e849",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk = pd.read_excel(\"../data/fluidmilk.xlsx\", skiprows = 1)\n",
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b9684",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk.columns = milk.columns.str.replace('\\n', '')\n",
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85abfb81",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk = milk.rename(columns=lambda x: x.strip(' 012'))\n",
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81ce1e",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk = milk.rename(columns = {'Unnamed:': 'Year'})\n",
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9ef5e",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk.columns.values[[2,3,5,6]] = np.array(['Reduced', 'Low', \n",
    "                                            'Flavored Whole', 'Flavored Other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862fa2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014a438",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb94ddc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk = milk.set_index('Year')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4232b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ebaf4c",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "milk = pd.read_excel(\"../data/fluidmilk.xlsx\", skiprows = 1)\n",
    "milk.columns = milk.columns.str.replace('\\n', '')\n",
    "milk = milk.rename(columns=lambda df: df.strip(' 12'))\n",
    "milk.columns.values[[0,2,3,5,6]] = np.array(['Year', 'Reduced', 'Low', \n",
    "                                             'Flavored Whole', 'Flavored Other'])\n",
    "milk = milk[:-4] # get rid of the last four rows\n",
    "milk = milk.set_index(\"Year\") \n",
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10cb953",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk = milk.stack() \n",
    "milk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb11e1b",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc522c5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk = milk.reset_index()\n",
    "milk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk.columns.values[[False, True, True]] = np.array([\"Kind\", \"Sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c4173",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a79eca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "milk.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6f0bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Today's Topics\n",
    "\n",
    " - Concurrency\n",
    "     - Threads and Processes\n",
    "     - I/O-Concurrency\n",
    "         - `threading`\n",
    "     - CPU-Concurrency (Parallelization)\n",
    "         - `multiprocessing` \n",
    "         - `Spark`\n",
    " \n",
    "### References\n",
    "- [SuperFastPython](https://superfastpython.com/thread-vs-process/) by Jason Brownlee\n",
    "- [An introduction to parallel programming](https://sebastianraschka.com/Articles/2014_multiprocessing.html) by Sebastian Raschka\n",
    "- [Speed Up Your Python Program With Concurrency](https://realpython.com/python-concurrency/) by Jim Anderson\n",
    "- [An Intro to Threading in Python](https://realpython.com/intro-to-python-threading/) by Jim Anderson\n",
    "- [3 Methods for Parallelization in Spark](https://towardsdatascience.com/3-methods-for-parallelization-in-spark-6a1a4333b473) by Ben Weber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44dc81e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Threads and Processes\n",
    "\n",
    "A computer can have multiple CPUs, each CPU has multiple cores (e.g., two quad-core CPUs). \n",
    "All the CPUs are connected to memory (e.g., 64G memory). \n",
    "CPU cores can execute in parallel. \n",
    "\n",
    "<div>\n",
    "<img src=\"./source/fig1.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58803ce1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A __process__ is the *operating system’s spawned and controlled entity that encapsulates an executing application* ([Breshears: The Art of Concurrency](https://amzn.to/3J74TRr)). \n",
    "\n",
    "A __thread__ is a path of execution which belongs to a process. \n",
    "\n",
    "Each thread belongs to a process. In single-threaded processes, the process contains one thread. In multithreaded processes, the process contains more than one thread, and the process is accomplishing a number of things at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed164f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Threads can share memory within a process. This means that functions executed in new threads can access the same data and state. These might be global variables or data shared via function arguments. As such, sharing state between threads is straightforward.\n",
    "\n",
    "Threads are sometimes called lightweight processes because they have their own stack but can access shared data. \n",
    "\n",
    "<div>\n",
    "<img src=\"./source/fig3.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f70e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On the other hand, processes are 'share nothing', i.e., they independently execute without sharing memory or state. This makes it easier to turn into a distributed application, but typically, sharing data between processes requires explicit mechanisms.\n",
    "\n",
    "<div>\n",
    "<img src=\"./source/fig4.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0677f060",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Python allows to execute code using the principle of global interpreter lock (GIL). This means that only one thread can be executed at a time. This simplifies implementation, but makes it more difficult to execute code concurrently. \n",
    "\n",
    "Today, we will explore the advantages of executing multiple processes and threads and discuss under what circumstances which approach is most adequate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352750d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are two major kind of tasks, that will slow down your program: CPU-bound and I/O-bound.\n",
    "\n",
    "I/O-bound tasks cause your program to slow down because it frequently must wait for input/output (I/O) from some external resource. They arise when your program interacts with other sources, i.e., when your are *requesting* data from another source. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acafebe",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/IOBound.4810a888b457.png style=\"width: 1700px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d51c2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "CPU-bound tasks are those that require a lot of *computational* effort to complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792b789",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/CPUBound.d2d32cb2626c.png style=\"width: 1700px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc078db",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We will use threads and the module `threading` for I/O-bound tasks and processes and the module `multiprocessing` for CPU-bound tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b8610",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### I/O-Concurrency\n",
    "\n",
    "We’ll start with a non-concurrent version of this a I/O-bound task. Namely, we will use `request` to request data from a [website](https://anson.ucdavis.edu/~kramling/). For `requets.Session`, see [here](https://requests.readthedocs.io/en/latest/user/advanced/) and [docs](https://requests.readthedocs.io/en/latest/api/?#requests.Session). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a93301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests, time\n",
    "\n",
    "def download_site(url, session):\n",
    "    session.get(url) # fetch information from url \n",
    "    # ... do something ... \n",
    "    \n",
    "def download_all_sites(sites):\n",
    "    session = requests.Session()\n",
    "    [download_site(url, session) for url in sites]\n",
    "        \n",
    "def task(): \n",
    "    sites = [\"https://anson.ucdavis.edu/~kramling/\"] * 80\n",
    "    start_time = time.time()\n",
    "    download_all_sites(sites)\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bbfd47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764664888381958\n"
     ]
    }
   ],
   "source": [
    "task()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4079ebd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will now use concurrent threads that accomplish the same task, retrieving information by executing `requests.get` more efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284bab80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import concurrent.futures, threading\n",
    "\n",
    "thread_local = threading.local() # instantiates thread to create local data (here: session-attr.)\n",
    "\n",
    "def download_site(url):\n",
    "    session = get_session()\n",
    "    session.get(url)\n",
    "    # ... do something ... \n",
    "\n",
    "def download_all_sites(sites):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        executor.map(download_site, sites)\n",
    "\n",
    "def get_session():\n",
    "    '''Create a new requests.Session if there is none in thread_local'''\n",
    "    if not hasattr(thread_local, \"session\"): \n",
    "        thread_local.session = requests.Session()\n",
    "    return thread_local.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a96540c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14759087562561035\n"
     ]
    }
   ],
   "source": [
    "task()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22615b2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have created a `concurrent.futures.ThreadPoolExecutor`. It creates five threads that are run concurrently. \n",
    "\n",
    "Also, each thread will become its own separate `requests.Session`. This is one of the interesting and difficult issues with threading. Because the operating system is in control of switching between threads, any data that is shared between the threads needs to be protected, or thread-safe. Unfortunately `requests.Session` is not thread-safe. If untreated, *race conditions* can produce hard-to-detect bugs. \n",
    "\n",
    "Here, we use `threading.local()` to instantiate an object that looks like a global but is specific to each individual thread. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bd665",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The code above is faster than the non-concurrent version, because the I/O-bound has been circumvented. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b31dc",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/Threading.3eef48da829e.png style=\"width: 1600px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a57dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CPU-Concurrency (Parallelization)\n",
    "\n",
    "The above example of concurrency run only on a single CPU. This is due to the GIL. The `multiprocessing` module breaks down that barrier and runs code across multiple CPUs. \n",
    "\n",
    "It does this by creating a new instance of the Python interpreter (a new process) to run on each CPU and then farming out part of your program to run on it.  Bringing up a separate Python interpreter is not as fast as starting a new thread in the current Python interpreter. Regarding `.set_start_method`, see [here](https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801a8412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9bebb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2803640365600586\n"
     ]
    }
   ],
   "source": [
    "session = None\n",
    "multiprocessing.set_start_method(\"fork\", True) # new process will be a copy from previous process\n",
    "\n",
    "def set_global_session():\n",
    "    global session\n",
    "    if not session:\n",
    "        session = requests.Session()\n",
    "\n",
    "def download_site(url):\n",
    "    session.get(url)\n",
    "    # ... do something ... \n",
    "\n",
    "def download_all_sites(sites):\n",
    "    with multiprocessing.Pool(initializer=set_global_session, processes = 8) as pool: # change processes!\n",
    "        pool.map(download_site, sites)\n",
    "    \n",
    "task()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503bc19",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We may even be faster than with `threading`, since we are running up to 8 processes in parallel, but `multiprocessing` cannot scale beyond the number of cores in your local machine. \n",
    "The default argument `processes` of `multiprocessing.pool.Pool` ([docs](https://docs.python.org/3/library/multiprocessing.html?#module-multiprocessing.pool)), is the number of available cores on the machine. \n",
    "\n",
    "Remember that each process has its own memory space (share-nothing). That means that they cannot share things like a `requests.Session` object. We don’t want to create a new Session each time the function is called, you want to create one for each process, which calls `request.get` multiple times after another. \n",
    "\n",
    "The `initializer` function parameter is built for just this case. We initialize a global `session` variable to hold the single `requests.Session` *for each process*. Because each process has its own memory space, the global for each one will be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e2832",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/MProc.7cf3be371bbc.png style=\"width: 1600px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05368937",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This course will deal with fetching information from the web, usually via requests. While these requests will usually be bound by third partys who maintain the servers we are requesting from as well, they are in essence I/O-bound task. `multiprocessing` however is useful for CPU-bound tasks. Consequently, lets consider a computational problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edef6c4a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For the purposes of our example, we’ll use a somewhat silly function to create something that takes a long time to run on the CPU. This function computes the sum of the squares of each number from 0 to the passed-in value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1406ac99",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def problem(number):\n",
    "    return sum(i * i for i in range(number))\n",
    "\n",
    "def find_sums(numbers):\n",
    "    for number in numbers:\n",
    "        problem(number)\n",
    "\n",
    "def task():\n",
    "    numbers = [5_000_000 + x for x in range(20)]\n",
    "    start_time = time.time()\n",
    "    find_sums(numbers)\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9ef724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.951680898666382\n"
     ]
    }
   ],
   "source": [
    "task()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d247d32",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This code calls `cpu_bound` 20 times with a different large number each time. It does all of this on a single thread in a single process on a single CPU. The execution timing diagram looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c315448",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/CPUBound.d2d32cb2626c.png style=\"width: 1600px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55b3f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since there is no I/O waiting time, `threading` will not speed up this problem. We can however speed the computation by using our multiple cores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a87f2626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiprocessing.set_start_method(\"fork\", True) # has already been set\n",
    "def find_sums(numbers):\n",
    "    pool = multiprocessing.Pool()\n",
    "    return pool.map(problem, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83043ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.599679946899414\n"
     ]
    }
   ],
   "source": [
    "task()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceaa426",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This code is similar as for the I/O-bound problem, but here you don’t need to worry about the `requests.Session` object. Notably, the speed-up is not equal to the number of cores, as each process has to set up its own Python interpreter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b72c9cc",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://files.realpython.com/media/CPUMP.69c1a7fad9c4.png style=\"width: 1600px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1facef36",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While this codes is easy and fast. All the single processes are automatically taken care of with `multiprocessing.Pool`. The results returned by `problem` are gathered by `multiprocessing.map` as a <kbd>list</kbd> type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c97ec85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_sums(range(0, 4)) # returns a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92cea47",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "However, many solution require communication between the processes. This can add some complexity to your solution that a non-concurrent program would not need to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248b939",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A `multiprocessing.Queue` object provides a mechanism to pass data between a parent process and the descendent processes of it. It adheres the *first in first out* principle. We can retrieve with the `multiprocessing.get` method and set with the `multiprocessing.put` method. \n",
    "\n",
    "<div>\n",
    "<img src=https://media.geeksforgeeks.org/wp-content/uploads/multiprocessing-python-4.png style=\"width: 1400px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d2430a",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "q = multiprocessing.Queue()\n",
    "def myfun(q, i): \n",
    "    q.put(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4c28dee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Process name='Process-25' parent=8580 initial>,\n",
       " <Process name='Process-26' parent=8580 initial>,\n",
       " <Process name='Process-27' parent=8580 initial>,\n",
       " <Process name='Process-28' parent=8580 initial>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize process\n",
    "processes = [multiprocessing.Process(target=myfun, args = (q, i)) for i in range(4)]\n",
    "processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ce64c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peter             8580   7.9  0.7 35486988  58624   ??  Ss    6:37PM   0:09.09 /Users/peter/opt/anaconda3/bin/python -m ipykernel_launcher -f /Users/peter/Library/Jupyter/runtime/kernel-d7b33bd9-2084-42ef-b03c-d4c5de79bf2f.json\r\n"
     ]
    }
   ],
   "source": [
    "!ps aux | grep \"[8]580\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f44bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The processess are initialized but not yet executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d332f66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run processes\n",
    "for process in processes:\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a71474cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join processes\n",
    "for process in processes:\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b4480",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The main purpose of `multiprocessing.join` ([docs](https://docs.python.org/3/library/multiprocessing.html?#multiprocessing.Process.join)) is to ensure that a child process has completed before the main process does anything that depends on the work of the child process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a834ede7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Process name='Process-25' pid=8636 parent=8580 stopped exitcode=0>,\n",
       " <Process name='Process-26' pid=8637 parent=8580 stopped exitcode=0>,\n",
       " <Process name='Process-27' pid=8638 parent=8580 stopped exitcode=0>,\n",
       " <Process name='Process-28' pid=8639 parent=8580 stopped exitcode=0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9464f3",
   "metadata": {},
   "source": [
    "The value `exitcode=0` means that the process has been completed successfully, without error ([docs](https://docs.python.org/3/library/multiprocessing.html?#multiprocessing.Process.exitcode)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d14c5659",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85f30a3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[q.get() for process in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9047275e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77178fd1",
   "metadata": {},
   "source": [
    "While `multiprocessing` allows you to steer the processes directly, many statistical problems are already implemented and ready for parallel computing, e.g. via `Spark`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b509a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spark\n",
    "\n",
    "Apache Spark is a computational engine that works with huge sets of data by processing them in parallel and batch systems. Spark is written in Scala, and [PySpark](https://www.dominodatalab.com/data-science-dictionary/pyspark) was released to support the collaboration of Spark and Python. \n",
    "\n",
    "The key data type used in PySpark is the Spark dataframe. This object can be thought of as a table distributed across a cluster, and has functionality that is similar to dataframes in `pandas`. If you want to do distributed computation using `PySpark`, then you’ll need to perform operations on Spark dataframes and not other Python data types.\n",
    "\n",
    "Here we explore how to perform tasks using `PySpark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e677095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a93ce",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We consider a simple regression model for predicting house prices. Lets consider the non-serialized version first: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca27e6fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "165dd157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the california housing data set\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# convert to a Pandas Data Frame\n",
    "housing_pd = pd.DataFrame(data= np.c_[housing['data'],housing['target']], \n",
    "                          columns= np.append(housing['feature_names'], 'target')).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7274f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "699c21de",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>2.2054</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.271293</td>\n",
       "      <td>1.223975</td>\n",
       "      <td>895.0</td>\n",
       "      <td>2.823344</td>\n",
       "      <td>34.00</td>\n",
       "      <td>-118.33</td>\n",
       "      <td>1.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>6.3132</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.735363</td>\n",
       "      <td>0.990632</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>3.266979</td>\n",
       "      <td>37.69</td>\n",
       "      <td>-121.91</td>\n",
       "      <td>2.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11352</th>\n",
       "      <td>2.6442</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.134259</td>\n",
       "      <td>1.032407</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>5.319444</td>\n",
       "      <td>33.75</td>\n",
       "      <td>-117.92</td>\n",
       "      <td>1.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18324</th>\n",
       "      <td>5.9277</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.356502</td>\n",
       "      <td>1.002242</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>2.573991</td>\n",
       "      <td>37.44</td>\n",
       "      <td>-122.13</td>\n",
       "      <td>4.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>3.7778</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.035928</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>391.0</td>\n",
       "      <td>2.341317</td>\n",
       "      <td>33.81</td>\n",
       "      <td>-118.39</td>\n",
       "      <td>4.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "5016   2.2054      47.0  5.271293   1.223975       895.0  2.823344     34.00   \n",
       "963    6.3132      18.0  6.735363   0.990632      1395.0  3.266979     37.69   \n",
       "11352  2.6442      23.0  4.134259   1.032407      1149.0  5.319444     33.75   \n",
       "18324  5.9277      38.0  6.356502   1.002242      1148.0  2.573991     37.44   \n",
       "8767   3.7778      35.0  6.035928   0.988024       391.0  2.341317     33.81   \n",
       "\n",
       "       Longitude  target  \n",
       "5016     -118.33   1.215  \n",
       "963      -121.91   2.592  \n",
       "11352    -117.92   1.563  \n",
       "18324    -122.13   4.466  \n",
       "8767     -118.39   4.875  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adc23d69",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/10 18:41:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36d44ab6",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peter/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/Users/peter/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "# convert to a Spark data frame\n",
    "housing_sp = spark.createDataFrame(housing_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7cddd49",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "features = housing_sp.schema.names[:]\n",
    "target = features.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b49c77cb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# convert to vector representation for MLlib\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\" )\n",
    "housing = assembler.transform(housing_sp).select('features', 'target') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce0d1c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "See [docs](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0753108",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# linear regresion with Spark\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a18276e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# linear regression with penalization\n",
    "lr = LinearRegression(labelCol=\"target\", featuresCol=\"features\", \n",
    "                      elasticNetParam = 1.0, # lasso / l1-penalization\n",
    "                      standardization = True, \n",
    "                      fitIntercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d0020ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lrparamGrid = (ParamGridBuilder()\n",
    "               .addGrid(lr.regParam, [0.001, 0.01, 0.1, 0.5, 1.0, 2.0])\n",
    "               .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fccffb11",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "lrevaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"target\", metricName=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbc9bbe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "lrcv = CrossValidator(estimator = lr,\n",
    "                      estimatorParamMaps = lrparamGrid,\n",
    "                      evaluator = lrevaluator,\n",
    "                      numFolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "457ad1c1",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/10 18:41:36 WARN TaskSetManager: Stage 0 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/10 18:41:37 WARN InstanceBuilder$JavaBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/10/10 18:41:37 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/10/10 18:41:37 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 1 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 2 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 3 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 4 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 5 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 6 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 7 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 8 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 9 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 10 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:38 WARN TaskSetManager: Stage 11 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 12 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 13 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 14 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 15 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 16 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 17 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 18 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 19 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 20 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 21 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 22 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 23 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 24 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 25 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:39 WARN TaskSetManager: Stage 26 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 27 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 28 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 29 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 30 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 31 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 32 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 33 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 34 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 35 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 36 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 37 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 38 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 39 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 40 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 41 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 42 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:40 WARN TaskSetManager: Stage 43 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 44 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 45 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 46 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 47 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 48 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 49 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 50 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 51 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 52 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 53 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 54 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 55 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 56 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 57 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 58 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 59 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 60 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:41 WARN TaskSetManager: Stage 61 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 62 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 63 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 64 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 65 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 66 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 67 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 68 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 69 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 70 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 71 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 72 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 73 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 74 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 75 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 76 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 77 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 78 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 79 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:42 WARN TaskSetManager: Stage 80 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 81 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 82 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 83 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 84 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 85 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 86 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 87 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 88 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 89 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 90 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/10/10 18:41:43 WARN TaskSetManager: Stage 91 contains a task of very large size (1698 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "# Run cross validations\n",
    "lrcvModel = lrcv.fit(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc51b6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "See [docs](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegressionTrainingSummary.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "640c26fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6239342564332631"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Model Summary Statistics\n",
    "lrcvSummary = lrcvModel.bestModel.summary\n",
    "lrcvSummary.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1231f009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.437, 0.0145, -0.1131, 0.4914, 0.0, -0.0041, -0.0224, -0.0066])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcvModel.bestModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a05c85cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'target']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_sp.schema.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c15a9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary \n",
    "\n",
    "- There are I/O- and CPU-bound problems\n",
    "- Use `threading` for I/O-bound problems, `multiprocessing` for CPU-bound problems\n",
    "- Communication between processes is cumbersome\n",
    "- For many CPU-bound tasks, there may be implemented solutions. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "rise": {
   "progress": true,
   "scroll": true,
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
