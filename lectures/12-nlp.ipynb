{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff704263",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STA 141B Data & Web Technologies for Data Analysis\n",
    "\n",
    "### Lecture 12, 2/20/24, Natural language processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb3382",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Today's topics\n",
    "- Natural Language Processing\n",
    "     - `nltk` package\n",
    "     - Tokenization\n",
    "     - Regular Expressions\n",
    "     - Standardizing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f66f37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ressources\n",
    "- [Natural Language Processing with Python][nlpp], chapters 1-3. Beware: the print version is for Python 2.\n",
    "- [Scikit-Learn Documentation][skl], especially the section about [Text Feature Extraction](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "\n",
    "\n",
    "[PDSH]: https://jakevdp.github.io/PythonDataScienceHandbook/\n",
    "[ProGit]: https://git-scm.com/book/\n",
    "[nlpp]: https://www.nltk.org/book/\n",
    "[atap]: https://search.library.ucdavis.edu/primo-explore/fulldisplay?docid=01UCD_ALMA51320822340003126&context=L&vid=01UCD_V1&search_scope=everything_scope&tab=default_tab&lang=en_US\n",
    "[skl]: https://scikit-learn.org/stable/documentation.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2af2f1",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "\n",
    "A _natural language_ is a language people use to communicate, like English, Spanish, or Mandarin. These languages evolved over thousands of years and do not have simple, explicit rules.\n",
    "\n",
    "_Natural language processing_ (NLP) means using a computer to analyze, manipulate, or synthesize natural language. Some examples of NLP tasks are:\n",
    "* Translating from one language to another\n",
    "* Recognizing speech or handwriting\n",
    "* Tagging sentences with metadata, such as parts of speech (verbs, nouns, etc) or sentiment\n",
    "* Extracting information or computing statistics from text\n",
    "\n",
    "Compared to artificial languages like Python and XML, it's much more difficult to extract information from natural languages. NLP is a wide field; we only have time to learn the absolute basics. If you want to learn more, consider reading the entire [Natural Language Processing with Python][nlpp] book or taking a class in computational linguistics.\n",
    "\n",
    "[nlpp]: https://www.nltk.org/book/\n",
    "\n",
    "\n",
    "#### The Python NLP Ecosystem\n",
    "\n",
    "There are lots of Python packages for NLP (try searching online)! A few popular ones are:\n",
    "\n",
    "* [Natural Language Tool Kit][nltk] (`nltk`) is the most popular. It's designed for learning and research, so it's well-documented and has lots of features. We will use `nltk` for this class. \n",
    "* [TextBlob][textblob] is a \"simplified\" package. It has a nicer interface than NLTK, but less features.\n",
    "* [SpaCy][spacy] is a \"production-ready\" package, and the fastest of all the packages listed here. Useful for working with large natural language datasets.\n",
    "* [gensim][gensim] is a package for creating topic models, which are a kind of statistical model that predict the topics of a text.\n",
    "\n",
    "We're going to learn `nltk`, but you might want to try some of the others if your project involves NLP.\n",
    "\n",
    "[Stanford's Core NLP][CoreNLP] library is at the cutting edge of NLP research. It's developed in Java, but several Python packages provide an interface (such as [pynlp][] and [stanford-corenlp][]).\n",
    "\n",
    "[nltk]: https://www.nltk.org/\n",
    "[spacy]: https://spacy.io/\n",
    "[textblob]: https://textblob.readthedocs.io/en/dev/\n",
    "[gensim]: https://radimrehurek.com/gensim/\n",
    "[CoreNLP]: https://stanfordnlp.github.io/CoreNLP/\n",
    "[pynlp]: https://github.com/sina-al/pynlp\n",
    "[stanford-corenlp]: https://github.com/Lynten/stanford-corenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26945e94",
   "metadata": {},
   "source": [
    "#### Corpora and Documents\n",
    "\n",
    "A _document_ is a single body text. When working with natural language data, documents are the unit of observation.\n",
    "\n",
    "What you choose as a document depends on the purpose of your analysis. If you're studying how people react to news on Twitter, it makes sense to use individual tweets as documents. If you're studying how animals are portrayed in 19th-century literature, you could use individual novels as documents.\n",
    "\n",
    "A _corpus_ is a collection of documents. In other words, a corpus is a dataset.\n",
    "\n",
    "`nltk` provides some example corpora in the `nltk.corpus` submodule. The documentation gives a [complete list](http://www.nltk.org/nltk_data/). Most have to be downloaded with `nltk.download()` before use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2032bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /Users/peter/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "\n",
    "# Download books from Project Gutenberg\n",
    "nltk.download(\"gutenberg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b660f8",
   "metadata": {},
   "source": [
    "The `.fileids()` method lists the documents in a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39931181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e86920f",
   "metadata": {},
   "source": [
    "Lets talk about [whales](https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2H_4_0002). The `.raw()` method returns the raw text for a single document. Specify the document by its file ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52e2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby = nltk.corpus.gutenberg.raw(\"melville-moby_dick.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3c4437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Moby Dick by Herman Melville 1851]\\r\\n\\r\\n\\r\\nETYMOLOGY.\\r\\n\\r\\n(Supplied by a Late Consumptive Usher to a Grammar School)\\r\\n\\r\\nThe pale Usher--threadbare in coat, heart, body, and brain; I see him\\r\\nnow.  He was ever dusting his old lexicons and grammars, with a queer\\r\\nhandkerchief, mockingly embellished with all the gay flags of all the\\r\\nknown nations of the world.  He loved to dust his old grammars; it\\r\\nsomehow mildly reminded him of his mortality.\\r\\n\\r\\n\"While you take in hand to school others, and to teach them by what\\r\\nname a whale-fish is to be called in our tongue leaving out, through\\r\\nignorance, the letter H, which almost alone maketh the signification\\r\\nof the word, you deliver that which is not true.\" --HACKLUYT\\r\\n\\r\\n\"WHALE. ... Sw. and Dan. HVAL.  This animal is named from roundness\\r\\nor rolling; for in Dan. HVALT is arched or vaulted.\" --WEBSTER\\'S\\r\\nDICTIONARY\\r\\n\\r\\n\"WHALE. ... It is more immediately from the Dut. and Ger. WALLEN;\\r\\nA.S. WALW-IAN, to roll, to wallow.\" --RICHARDSON\\'S DICTIONARY\\r\\n\\r\\nKETOS,               GREEK.\\r\\nCETUS,               LATIN.\\r\\nWHOEL,               ANGLO-SAXON.\\r\\nHVALT,               DANISH.\\r\\nWAL,                 DUTCH.\\r\\nHWAL,                SWEDISH.\\r\\nWHALE,               ICELANDIC.\\r\\nWHALE,               ENGLISH.\\r\\nBALEINE,             FRENCH.\\r\\nBALLENA,             SPANISH.\\r\\nPEKEE-NUEE-NUEE,     FEGEE.\\r\\nPEKEE-NUEE-NUEE,     ERROMANGOAN.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nEXTRACTS (Supplied by a Sub-Sub-Librarian).\\r\\n\\r\\nIt will be seen that this mere painstaking burrower and grub-worm of\\r\\na poor devil of a Sub-Sub appears to have gone through the long\\r\\nVaticans and street-stalls of the earth, picking up whatever random\\r\\nallusions to whales he could anyways find in any book whatsoever,\\r\\nsacred or profane.  Therefore you must not, in every case at least,\\r\\ntake the higgledy-piggledy whale statements, however authentic, in\\r\\nthese extracts, for veritable gospel cetology.  Far from it.  As\\r\\ntouching the ancient authors generally, as well as the poets here\\r\\nappearing, these extracts are s'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby[0:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083c5740",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "A _token_ is a sequence of characters to be treated as a group. Tokens are the unit of analysis for an indvidual document.\n",
    "\n",
    "Tokens can represent paragraphs, sentences, words, or something else. Most of the time, tokens will be words.\n",
    "\n",
    "When you analyze a document, the first step will usually be to split the document into tokens. Functions that do this are called _tokenizers_, and this process is called _tokenization_.\n",
    "\n",
    "The `nltk.sent_tokenize()` function splits a document into sentences, and the `nltk.word_tokenize()` function splits a document into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb69134a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nltk.sent_tokenize(moby))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "647f0a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Moby Dick by Herman Melville 1851]\\r\\n\\r\\n\\r\\nETYMOLOGY.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(moby)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f2cd3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Call me Ishmael.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(moby)[283]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe1b519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(moby)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ada67",
   "metadata": {},
   "source": [
    "Corpora also have `.sents()` and `.word()` methods for tokenization. These methods are specialized to the corpus, so they sometimes use the different strategies than `sent_tokenize()` and `word_tokenize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f8f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nltk.corpus.gutenberg.sents(\"melville-moby_dick.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f771fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c79083f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.words(\"melville-moby_dick.txt\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97988f44",
   "metadata": {},
   "source": [
    "### Strings and String Methods\n",
    "\n",
    "Lets continue talking about \t&#128011;. How does word tokenization actually work? The simplest strategy is to split at whitespace. You can do this with Python's built-in string methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e10654bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851]',\n",
       " 'ETYMOLOGY.',\n",
       " '(Supplied',\n",
       " 'by',\n",
       " 'a']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby.split()[:10] # splits on whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80036a65",
   "metadata": {},
   "source": [
    "Splitting on whitespace doesn't handle punctuation. You can use regular expressions to split on more complex patterns. Python's built-in `re` module provides regular expression functions [here](https://docs.python.org/3/library/re.html).\n",
    "\n",
    "```\n",
    "re.split(pattern, string, maxsplit=0, flags=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4de9bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d22b5466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Moby Dick by Herman Melville 1851]\\r\\n\\r\\n\\r\\nETYMOLOGY.\\r\\n\\r\\n(Supplied by a Late Consumptive Usher to a Gr'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac2d7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'can', 't', '', 'let', 'Go']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\"[, :;']\", 'I can\\'t, let:Go')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e59b4d",
   "metadata": {},
   "source": [
    "What if we also want to split at newlines?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b36f30",
   "metadata": {},
   "source": [
    "### Escape Sequences and Raw Strings\n",
    "\n",
    "In Python strings, backslash `\\` marks the beginning of an _escape sequence_. Escape sequences are special codes for writing characters that you can't otherwise type. For example, `\\n` is a new line character and `\\t` is a tab character.\n",
    "\n",
    "Since `\\` has a special meaning in strings, to write a literal `\\` you must use the escape sequence `\\\\`.\n",
    "\n",
    "You can see the actual characters in a string by printing the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42b462ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "world.\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\\nworld.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40378afa",
   "metadata": {},
   "source": [
    "The regular expression (Regex) language is independent of Python and also uses backslash `\\` to mark the beginning of an escape sequence. Regex escape sequences disable special behavior for characters. For example, `.` matches any character, but `\\.` only matches a literal `.`.\n",
    "\n",
    "As a result, writing a regular expression in an ordinary Python string is awkward. For example, to match a literal `\\`, we need to write `\\\\` in regular expressions, which is `\\\\\\\\` in an ordinary Python string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f991bd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9125a",
   "metadata": {},
   "source": [
    "Python provides _raw strings_, where `\\` has no special meaning for Python, to help solve this problem. You can create a raw string by putting an `r` before the starting quote:\n",
    "\n",
    "More about raw strings: [here](https://www.journaldev.com/23598/python-raw-string#:~:text=Python%20raw%20string%20is%20created,treated%20as%20an%20escape%20character.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53a7d6ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (835106092.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/fh/hvkm2z9n7631q5058px_kqg80000gr/T/ipykernel_53232/835106092.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(r\"\\\")\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "print(r\"\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978292ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r\"\\\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r'\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Hi\\nHello'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0514bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_s = r'Hi\\nHello'\n",
    "raw_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd7b22",
   "metadata": {},
   "source": [
    "Even raw strings can't end in `\\;` this is a limitation of the Python parser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60232c18",
   "metadata": {},
   "source": [
    "Now we can write a better regular expression to split with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(re.split(r\"[ \\[\\](),.:;!?'\\n\\r]\", moby)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac155f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(r\"\\s\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49226b32",
   "metadata": {},
   "source": [
    "### Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a004f0",
   "metadata": {},
   "source": [
    "The regular expressions language includes _character classes_ that describe common sets of characters. The whitespace class `\\s` and the word class `\\w` are useful here (see [Reference](https://docs.python.org/3/library/re.html)). So to split on any whitespace character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ca632",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = r'[ ,.:;!\\n\\r]'\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869bfb3f",
   "metadata": {},
   "source": [
    "moby[:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faa9e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea51be4",
   "metadata": {},
   "source": [
    "In a raw string, `re.split` looks for regex escapes; in a non-raw string, the function looks for the literal ASCII character. If these coincide, the string does not have to be converted to a raw string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b06e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re.split(\"[ \\[\\],.:;!'()\\n\\r-]\", moby) # note the '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78462934",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(\"[ \\[\\],.:;!'()\\n]\", moby) # note the '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8525b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(\"[ \\[\\],.:;!'()\\n]\", moby) # note the '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d94d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959067e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(\"[\\s\\[\\],.:;!'()-]\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea3263",
   "metadata": {},
   "source": [
    "Capitalizing a character classes inverts the meaning, so to split on all non-word characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b045b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(\"\\W+\", moby) # + matches 1 or more of the preceding characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a87887",
   "metadata": {},
   "source": [
    "`\\w` means _any word character_\n",
    "\n",
    "`+` Causes the resulting RE to match 1 or more repetitions of the preceding RE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b716f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(r\"\\W+\", \"the...dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38002b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(\"\\W+\", \"the,dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc616c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(r\"\\W+\", \"the,I:! dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(r\"\\W+\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a22a1",
   "metadata": {},
   "source": [
    "Rather than splitting the text, you can also approach the problem from the perspective of extracting tokens. The `findall()` function returns all matches for a regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a86938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re.findall(r\"\\w+\", \"The dog barked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d73b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\w\") # \\w is not a special python escape sequence, so it passes through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcdd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.split(r\"\\W+\", \"The dog barked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc4505",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"\\w+'?\\w{1}\", \"The dog's toy barked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"[\\w']+\", \"I think the dog's toy barked!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f2cbf",
   "metadata": {},
   "source": [
    "- `r\" \"`: read the string\n",
    "- `()+`: the patterns inside the parathesis should appear once or more\n",
    "- `\\w+`: the whole word\n",
    "- `|`: or\n",
    "\n",
    "More practice? [here](https://regex101.com/?fbclid=IwAR36UyAxywvpSvTOh7F-KYI72IZAVQ0wRcBc0OEOu6h4MifEf-iLcFedfyk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14c785cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " 'ETYMOLOGY',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar',\n",
       " 'School',\n",
       " 'The',\n",
       " 'pale',\n",
       " 'Usher',\n",
       " 'threadbare',\n",
       " 'in',\n",
       " 'coat',\n",
       " 'heart',\n",
       " 'body',\n",
       " 'and',\n",
       " 'brain',\n",
       " 'I',\n",
       " 'see',\n",
       " 'him',\n",
       " 'now',\n",
       " 'He',\n",
       " 'was',\n",
       " 'ever',\n",
       " 'dusting',\n",
       " 'his',\n",
       " 'old',\n",
       " 'lexicons',\n",
       " 'and',\n",
       " 'grammars',\n",
       " 'with',\n",
       " 'a',\n",
       " 'queer',\n",
       " 'handkerchief',\n",
       " 'mockingly',\n",
       " 'embellished',\n",
       " 'with',\n",
       " 'all',\n",
       " 'the',\n",
       " 'gay',\n",
       " 'flags',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'known',\n",
       " 'nations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'He',\n",
       " 'loved',\n",
       " 'to',\n",
       " 'dust',\n",
       " 'his',\n",
       " 'old',\n",
       " 'grammars',\n",
       " 'it',\n",
       " 'somehow',\n",
       " 'mildly',\n",
       " 'reminded',\n",
       " 'him',\n",
       " 'of',\n",
       " 'his',\n",
       " 'mortality',\n",
       " 'While',\n",
       " 'you',\n",
       " 'take',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'to',\n",
       " 'school',\n",
       " 'others',\n",
       " 'and',\n",
       " 'to',\n",
       " 'teach',\n",
       " 'them',\n",
       " 'by',\n",
       " 'what',\n",
       " 'name',\n",
       " 'a',\n",
       " 'whale',\n",
       " 'fish',\n",
       " 'is',\n",
       " 'to',\n",
       " 'be',\n",
       " 'called',\n",
       " 'in',\n",
       " 'our',\n",
       " 'tongue',\n",
       " 'leaving',\n",
       " 'out',\n",
       " 'through',\n",
       " 'ignorance',\n",
       " 'the',\n",
       " 'letter',\n",
       " 'H',\n",
       " 'which',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'maketh',\n",
       " 'the',\n",
       " 'signification',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word',\n",
       " 'you',\n",
       " 'deliver',\n",
       " 'that',\n",
       " 'which',\n",
       " 'is',\n",
       " 'not',\n",
       " 'true',\n",
       " 'HACKLUYT',\n",
       " 'WHALE',\n",
       " 'Sw',\n",
       " 'and',\n",
       " 'Dan',\n",
       " 'HVAL',\n",
       " 'This',\n",
       " 'animal',\n",
       " 'is',\n",
       " 'named',\n",
       " 'from',\n",
       " 'roundness',\n",
       " 'or',\n",
       " 'rolling',\n",
       " 'for',\n",
       " 'in',\n",
       " 'Dan',\n",
       " 'HVALT',\n",
       " 'is',\n",
       " 'arched',\n",
       " 'or',\n",
       " 'vaulted',\n",
       " 'WEBSTER',\n",
       " 'S',\n",
       " 'DICTIONARY',\n",
       " 'WHALE',\n",
       " 'It',\n",
       " 'is',\n",
       " 'more',\n",
       " 'immediately',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Dut',\n",
       " 'and',\n",
       " 'Ger',\n",
       " 'WALLEN',\n",
       " 'A',\n",
       " 'S',\n",
       " 'WALW',\n",
       " 'IAN',\n",
       " 'to',\n",
       " 'roll',\n",
       " 'to',\n",
       " 'wallow',\n",
       " 'RICHARDSON',\n",
       " 'S',\n",
       " 'DICTIONARY',\n",
       " 'KETOS',\n",
       " 'GREEK',\n",
       " 'CETUS',\n",
       " 'LATIN',\n",
       " 'WHOEL',\n",
       " 'ANGLO',\n",
       " 'SAXON',\n",
       " 'HVALT',\n",
       " 'DANISH',\n",
       " 'WAL',\n",
       " 'DUTCH',\n",
       " 'HWAL',\n",
       " 'SWEDISH',\n",
       " 'WHALE',\n",
       " 'ICELANDIC',\n",
       " 'WHALE',\n",
       " 'ENGLISH',\n",
       " 'BALEINE',\n",
       " 'FRENCH',\n",
       " 'BALLENA',\n",
       " 'SPANISH',\n",
       " 'PEKEE',\n",
       " 'NUEE',\n",
       " 'NUEE',\n",
       " 'FEGEE',\n",
       " 'PEKEE',\n",
       " 'NUEE',\n",
       " 'NUEE',\n",
       " 'ERROMANGOAN',\n",
       " 'EXTRACTS',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Sub',\n",
       " 'Sub',\n",
       " 'Librarian',\n",
       " 'It',\n",
       " 'will',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'that',\n",
       " 'this',\n",
       " 'mere',\n",
       " 'painstaking',\n",
       " 'burrower',\n",
       " 'and',\n",
       " 'grub',\n",
       " 'worm',\n",
       " 'of',\n",
       " 'a',\n",
       " 'poor',\n",
       " 'devil',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Sub',\n",
       " 'Sub',\n",
       " 'appears',\n",
       " 'to',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'through',\n",
       " 'the',\n",
       " 'long',\n",
       " 'Vaticans',\n",
       " 'and',\n",
       " 'street',\n",
       " 'stalls',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " 'picking',\n",
       " 'up',\n",
       " 'whatever',\n",
       " 'random',\n",
       " 'allusions',\n",
       " 'to',\n",
       " 'whales',\n",
       " 'he',\n",
       " 'could',\n",
       " 'anyways',\n",
       " 'find',\n",
       " 'in',\n",
       " 'any',\n",
       " 'book',\n",
       " 'whatsoever',\n",
       " 'sacred',\n",
       " 'or',\n",
       " 'profane',\n",
       " 'Therefore',\n",
       " 'you',\n",
       " 'must',\n",
       " 'not',\n",
       " 'in',\n",
       " 'every',\n",
       " 'case',\n",
       " 'at',\n",
       " 'least',\n",
       " 'take',\n",
       " 'the',\n",
       " 'higgledy',\n",
       " 'piggledy',\n",
       " 'whale',\n",
       " 'statements',\n",
       " 'however',\n",
       " 'authentic',\n",
       " 'in',\n",
       " 'these',\n",
       " 'extracts',\n",
       " 'for',\n",
       " 'veritable',\n",
       " 'gospel',\n",
       " 'cetology',\n",
       " 'Far',\n",
       " 'from',\n",
       " 'it',\n",
       " 'As',\n",
       " 'touching',\n",
       " 'the',\n",
       " 'ancient',\n",
       " 'authors',\n",
       " 'generally',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'poets',\n",
       " 'here',\n",
       " 'appearing',\n",
       " 'these',\n",
       " 'extracts',\n",
       " 'are',\n",
       " 'solely',\n",
       " 'valuable',\n",
       " 'or',\n",
       " 'entertaining',\n",
       " 'as',\n",
       " 'affording',\n",
       " 'a',\n",
       " 'glancing',\n",
       " 'bird',\n",
       " 's',\n",
       " 'eye',\n",
       " 'view',\n",
       " 'of',\n",
       " 'what',\n",
       " 'has',\n",
       " 'been',\n",
       " 'promiscuously',\n",
       " 'said',\n",
       " 'thought',\n",
       " 'fancied',\n",
       " 'and',\n",
       " 'sung',\n",
       " 'of',\n",
       " 'Leviathan',\n",
       " 'by',\n",
       " 'many',\n",
       " 'nations',\n",
       " 'and',\n",
       " 'generations',\n",
       " 'including',\n",
       " 'our',\n",
       " 'own',\n",
       " 'So',\n",
       " 'fare',\n",
       " 'thee',\n",
       " 'well',\n",
       " 'poor',\n",
       " 'devil',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Sub',\n",
       " 'Sub',\n",
       " 'whose',\n",
       " 'commentator',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Thou',\n",
       " 'belongest',\n",
       " 'to',\n",
       " 'that',\n",
       " 'hopeless',\n",
       " 'sallow',\n",
       " 'tribe',\n",
       " 'which',\n",
       " 'no',\n",
       " 'wine',\n",
       " 'of',\n",
       " 'this',\n",
       " 'world',\n",
       " 'will',\n",
       " 'ever',\n",
       " 'warm',\n",
       " 'and',\n",
       " 'for',\n",
       " 'whom',\n",
       " 'even',\n",
       " 'Pale',\n",
       " 'Sherry',\n",
       " 'would',\n",
       " 'be',\n",
       " 'too',\n",
       " 'rosy',\n",
       " 'strong',\n",
       " 'but',\n",
       " 'with',\n",
       " 'whom',\n",
       " 'one',\n",
       " 'sometimes',\n",
       " 'loves',\n",
       " 'to',\n",
       " 'sit',\n",
       " 'and',\n",
       " 'feel',\n",
       " 'poor',\n",
       " 'devilish',\n",
       " 'too',\n",
       " 'and',\n",
       " 'grow',\n",
       " 'convivial',\n",
       " 'upon',\n",
       " 'tears',\n",
       " 'and',\n",
       " 'say',\n",
       " 'to',\n",
       " 'them',\n",
       " 'bluntly',\n",
       " 'with',\n",
       " 'full',\n",
       " 'eyes',\n",
       " 'and',\n",
       " 'empty',\n",
       " 'glasses',\n",
       " 'and',\n",
       " 'in',\n",
       " 'not',\n",
       " 'altogether',\n",
       " 'unpleasant',\n",
       " 'sadness',\n",
       " 'Give',\n",
       " 'it',\n",
       " 'up',\n",
       " 'Sub',\n",
       " 'Subs',\n",
       " 'For',\n",
       " 'by',\n",
       " 'how',\n",
       " 'much',\n",
       " 'the',\n",
       " 'more',\n",
       " 'pains',\n",
       " 'ye',\n",
       " 'take',\n",
       " 'to',\n",
       " 'please',\n",
       " 'the',\n",
       " 'world',\n",
       " 'by',\n",
       " 'so',\n",
       " 'much',\n",
       " 'the',\n",
       " 'more',\n",
       " 'shall',\n",
       " 'ye',\n",
       " 'for',\n",
       " 'ever',\n",
       " 'go',\n",
       " 'thankless',\n",
       " 'Would',\n",
       " 'that',\n",
       " 'I',\n",
       " 'could',\n",
       " 'clear',\n",
       " 'out',\n",
       " 'Hampton',\n",
       " 'Court',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Tuileries',\n",
       " 'for',\n",
       " 'ye',\n",
       " 'But',\n",
       " 'gulp',\n",
       " 'down',\n",
       " 'your',\n",
       " 'tears',\n",
       " 'and',\n",
       " 'hie',\n",
       " 'aloft',\n",
       " 'to',\n",
       " 'the',\n",
       " 'royal',\n",
       " 'mast',\n",
       " 'with',\n",
       " 'your',\n",
       " 'hearts',\n",
       " 'for',\n",
       " 'your',\n",
       " 'friends',\n",
       " 'who',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'before',\n",
       " 'are',\n",
       " 'clearing',\n",
       " 'out',\n",
       " 'the',\n",
       " 'seven',\n",
       " 'storied',\n",
       " 'heavens',\n",
       " 'and',\n",
       " 'making',\n",
       " 'refugees',\n",
       " 'of',\n",
       " 'long',\n",
       " 'pampered',\n",
       " 'Gabriel',\n",
       " 'Michael',\n",
       " 'and',\n",
       " 'Raphael',\n",
       " 'against',\n",
       " 'your',\n",
       " 'coming',\n",
       " 'Here',\n",
       " 'ye',\n",
       " 'strike',\n",
       " 'but',\n",
       " 'splintered',\n",
       " 'hearts',\n",
       " 'together',\n",
       " 'there',\n",
       " 'ye',\n",
       " 'shall',\n",
       " 'strike',\n",
       " 'unsplinterable',\n",
       " 'glasses',\n",
       " 'EXTRACTS',\n",
       " 'And',\n",
       " 'God',\n",
       " 'created',\n",
       " 'great',\n",
       " 'whales',\n",
       " 'GENESIS',\n",
       " 'Leviathan',\n",
       " 'maketh',\n",
       " 'a',\n",
       " 'path',\n",
       " 'to',\n",
       " 'shine',\n",
       " 'after',\n",
       " 'him',\n",
       " 'One',\n",
       " 'would',\n",
       " 'think',\n",
       " 'the',\n",
       " 'deep',\n",
       " 'to',\n",
       " 'be',\n",
       " 'hoary',\n",
       " 'JOB',\n",
       " 'Now',\n",
       " 'the',\n",
       " 'Lord',\n",
       " 'had',\n",
       " 'prepared',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fish',\n",
       " 'to',\n",
       " 'swallow',\n",
       " 'up',\n",
       " 'Jonah',\n",
       " 'JONAH',\n",
       " 'There',\n",
       " 'go',\n",
       " 'the',\n",
       " 'ships',\n",
       " 'there',\n",
       " 'is',\n",
       " 'that',\n",
       " 'Leviathan',\n",
       " 'whom',\n",
       " 'thou',\n",
       " 'hast',\n",
       " 'made',\n",
       " 'to',\n",
       " 'play',\n",
       " 'therein',\n",
       " 'PSALMS',\n",
       " 'In',\n",
       " 'that',\n",
       " 'day',\n",
       " 'the',\n",
       " 'Lord',\n",
       " 'with',\n",
       " 'his',\n",
       " 'sore',\n",
       " 'and',\n",
       " 'great',\n",
       " 'and',\n",
       " 'strong',\n",
       " 'sword',\n",
       " 'shall',\n",
       " 'punish',\n",
       " 'Leviathan',\n",
       " 'the',\n",
       " 'piercing',\n",
       " 'serpent',\n",
       " 'even',\n",
       " 'Leviathan',\n",
       " 'that',\n",
       " 'crooked',\n",
       " 'serpent',\n",
       " 'and',\n",
       " 'he',\n",
       " 'shall',\n",
       " 'slay',\n",
       " 'the',\n",
       " 'dragon',\n",
       " 'that',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'ISAIAH',\n",
       " 'And',\n",
       " 'what',\n",
       " 'thing',\n",
       " 'soever',\n",
       " 'besides',\n",
       " 'cometh',\n",
       " 'within',\n",
       " 'the',\n",
       " 'chaos',\n",
       " 'of',\n",
       " 'this',\n",
       " 'monster',\n",
       " 's',\n",
       " 'mouth',\n",
       " 'be',\n",
       " 'it',\n",
       " 'beast',\n",
       " 'boat',\n",
       " 'or',\n",
       " 'stone',\n",
       " 'down',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'all',\n",
       " 'incontinently',\n",
       " 'that',\n",
       " 'foul',\n",
       " 'great',\n",
       " 'swallow',\n",
       " 'of',\n",
       " 'his',\n",
       " 'and',\n",
       " 'perisheth',\n",
       " 'in',\n",
       " 'the',\n",
       " 'bottomless',\n",
       " 'gulf',\n",
       " 'of',\n",
       " 'his',\n",
       " 'paunch',\n",
       " 'HOLLAND',\n",
       " 'S',\n",
       " 'PLUTARCH',\n",
       " 'S',\n",
       " 'MORALS',\n",
       " 'The',\n",
       " 'Indian',\n",
       " 'Sea',\n",
       " 'breedeth',\n",
       " 'the',\n",
       " 'most',\n",
       " 'and',\n",
       " 'the',\n",
       " 'biggest',\n",
       " 'fishes',\n",
       " 'that',\n",
       " 'are',\n",
       " 'among',\n",
       " 'which',\n",
       " 'the',\n",
       " 'Whales',\n",
       " 'and',\n",
       " 'Whirlpooles',\n",
       " 'called',\n",
       " 'Balaene',\n",
       " 'take',\n",
       " 'up',\n",
       " 'as',\n",
       " 'much',\n",
       " 'in',\n",
       " 'length',\n",
       " 'as',\n",
       " 'four',\n",
       " 'acres',\n",
       " 'or',\n",
       " 'arpens',\n",
       " 'of',\n",
       " 'land',\n",
       " 'HOLLAND',\n",
       " 'S',\n",
       " 'PLINY',\n",
       " 'Scarcely',\n",
       " 'had',\n",
       " 'we',\n",
       " 'proceeded',\n",
       " 'two',\n",
       " 'days',\n",
       " 'on',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'when',\n",
       " 'about',\n",
       " 'sunrise',\n",
       " 'a',\n",
       " 'great',\n",
       " 'many',\n",
       " 'Whales',\n",
       " 'and',\n",
       " 'other',\n",
       " 'monsters',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'appeared',\n",
       " 'Among',\n",
       " 'the',\n",
       " 'former',\n",
       " 'one',\n",
       " 'was',\n",
       " 'of',\n",
       " 'a',\n",
       " 'most',\n",
       " 'monstrous',\n",
       " 'size',\n",
       " 'This',\n",
       " 'came',\n",
       " 'towards',\n",
       " 'us',\n",
       " 'open',\n",
       " 'mouthed',\n",
       " 'raising',\n",
       " 'the',\n",
       " 'waves',\n",
       " 'on',\n",
       " 'all',\n",
       " 'sides',\n",
       " 'and',\n",
       " 'beating',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'before',\n",
       " 'him',\n",
       " 'into',\n",
       " 'a',\n",
       " 'foam',\n",
       " 'TOOKE',\n",
       " 'S',\n",
       " 'LUCIAN',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'HISTORY',\n",
       " 'He',\n",
       " 'visited',\n",
       " 'this',\n",
       " 'country',\n",
       " 'also',\n",
       " 'with',\n",
       " 'a',\n",
       " 'view',\n",
       " 'of',\n",
       " 'catching',\n",
       " 'horse',\n",
       " 'whales',\n",
       " 'which',\n",
       " 'had',\n",
       " 'bones',\n",
       " 'of',\n",
       " 'very',\n",
       " 'great',\n",
       " 'value',\n",
       " 'for',\n",
       " 'their',\n",
       " 'teeth',\n",
       " 'of',\n",
       " 'which',\n",
       " 'he',\n",
       " 'brought',\n",
       " 'some',\n",
       " 'to',\n",
       " 'the',\n",
       " 'king',\n",
       " 'The',\n",
       " 'best',\n",
       " 'whales',\n",
       " 'were',\n",
       " 'catched',\n",
       " 'in',\n",
       " 'his',\n",
       " 'own',\n",
       " 'country',\n",
       " 'of',\n",
       " 'which',\n",
       " 'some',\n",
       " 'were',\n",
       " 'forty',\n",
       " 'eight',\n",
       " 'some',\n",
       " 'fifty',\n",
       " 'yards',\n",
       " 'long',\n",
       " 'He',\n",
       " 'said',\n",
       " 'that',\n",
       " 'he',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'six',\n",
       " 'who',\n",
       " 'had',\n",
       " 'killed',\n",
       " 'sixty',\n",
       " 'in',\n",
       " 'two',\n",
       " 'days',\n",
       " 'OTHER',\n",
       " 'OR',\n",
       " 'OCTHER',\n",
       " 'S',\n",
       " 'VERBAL',\n",
       " 'NARRATIVE',\n",
       " 'TAKEN',\n",
       " 'DOWN',\n",
       " 'FROM',\n",
       " 'HIS',\n",
       " 'MOUTH',\n",
       " 'BY',\n",
       " 'KING',\n",
       " 'ALFRED',\n",
       " 'A',\n",
       " 'D',\n",
       " '890',\n",
       " 'And',\n",
       " 'whereas',\n",
       " 'all',\n",
       " 'the',\n",
       " 'other',\n",
       " 'things',\n",
       " 'whether',\n",
       " 'beast',\n",
       " 'or',\n",
       " 'vessel',\n",
       " 'that',\n",
       " 'enter',\n",
       " 'into',\n",
       " 'the',\n",
       " 'dreadful',\n",
       " 'gulf',\n",
       " 'of',\n",
       " 'this',\n",
       " 'monster',\n",
       " 's',\n",
       " 'whale',\n",
       " 's',\n",
       " 'mouth',\n",
       " 'are',\n",
       " 'immediately',\n",
       " 'lost',\n",
       " 'and',\n",
       " 'swallowed',\n",
       " 'up',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'gudgeon',\n",
       " 'retires',\n",
       " 'into',\n",
       " 'it',\n",
       " 'in',\n",
       " 'great',\n",
       " 'security',\n",
       " 'and',\n",
       " 'there',\n",
       " 'sleeps',\n",
       " 'MONTAIGNE',\n",
       " 'APOLOGY',\n",
       " 'FOR',\n",
       " 'RAIMOND',\n",
       " 'SEBOND',\n",
       " 'Let',\n",
       " 'us',\n",
       " 'fly',\n",
       " 'let',\n",
       " 'us',\n",
       " 'fly',\n",
       " 'Old',\n",
       " 'Nick',\n",
       " 'take',\n",
       " 'me',\n",
       " 'if',\n",
       " 'is',\n",
       " 'not',\n",
       " 'Leviathan',\n",
       " 'described',\n",
       " 'by',\n",
       " 'the',\n",
       " 'noble',\n",
       " 'prophet',\n",
       " 'Moses',\n",
       " 'in',\n",
       " 'the',\n",
       " 'life',\n",
       " 'of',\n",
       " 'patient',\n",
       " 'Job',\n",
       " 'RABELAIS',\n",
       " 'This',\n",
       " 'whale',\n",
       " 's',\n",
       " 'liver',\n",
       " 'was',\n",
       " 'two',\n",
       " 'cartloads',\n",
       " 'STOWE',\n",
       " 'S',\n",
       " 'ANNALS',\n",
       " 'The',\n",
       " 'great',\n",
       " 'Leviathan',\n",
       " 'that',\n",
       " 'maketh',\n",
       " 'the',\n",
       " 'seas',\n",
       " 'to',\n",
       " 'seethe',\n",
       " 'like',\n",
       " 'boiling',\n",
       " 'pan',\n",
       " 'LORD',\n",
       " 'BACON',\n",
       " 'S',\n",
       " 'VERSION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'PSALMS',\n",
       " 'Touching',\n",
       " 'that',\n",
       " 'monstrous',\n",
       " 'bulk',\n",
       " 'of',\n",
       " 'the',\n",
       " 'whale',\n",
       " 'or',\n",
       " 'ork',\n",
       " 'we',\n",
       " 'have',\n",
       " 'received',\n",
       " 'nothing',\n",
       " 'certain',\n",
       " 'They',\n",
       " 'grow',\n",
       " 'exceeding',\n",
       " 'fat',\n",
       " 'insomuch',\n",
       " 'that',\n",
       " 'an',\n",
       " 'incredible',\n",
       " 'quantity',\n",
       " 'of',\n",
       " 'oil',\n",
       " 'will',\n",
       " 'be',\n",
       " 'extracted',\n",
       " 'out',\n",
       " 'of',\n",
       " 'one',\n",
       " 'whale',\n",
       " 'IBID',\n",
       " 'HISTORY',\n",
       " 'OF',\n",
       " 'LIFE',\n",
       " 'AND',\n",
       " 'DEATH',\n",
       " 'The',\n",
       " 'sovereignest',\n",
       " 'thing',\n",
       " 'on',\n",
       " 'earth',\n",
       " 'is',\n",
       " 'parmacetti',\n",
       " 'for',\n",
       " 'an',\n",
       " 'inward',\n",
       " 'bruise',\n",
       " 'KING',\n",
       " 'HENRY',\n",
       " 'Very',\n",
       " 'like',\n",
       " 'a',\n",
       " 'whale',\n",
       " 'HAMLET',\n",
       " 'Which',\n",
       " 'to',\n",
       " 'secure',\n",
       " 'no',\n",
       " 'skill',\n",
       " 'of',\n",
       " 'leach',\n",
       " 's',\n",
       " 'art',\n",
       " 'Mote',\n",
       " 'him',\n",
       " 'availle',\n",
       " 'but',\n",
       " 'to',\n",
       " 'returne',\n",
       " 'againe',\n",
       " 'To',\n",
       " 'his',\n",
       " 'wound',\n",
       " 's',\n",
       " 'worker',\n",
       " 'that',\n",
       " 'with',\n",
       " 'lowly',\n",
       " 'dart',\n",
       " 'Dinting',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = re.findall(r\"\\w+\", moby)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fc987f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rful unbroken colt, with the mere appliance of a rope\\r\\ntied to the root of his tail.\" --A CHAPTER ON WHALING IN RIBS AND\\r\\nTRUCKS.\\r\\n\\r\\n\"On one occasion I saw two of these monsters (whales) probably male\\r\\nand female, slowly swimming, one after the other, within less than a\\r\\nstone\\'s throw of the shore\" (Terra Del Fuego), \"over which the beech\\r\\ntree extended its branches.\" --DARWIN\\'S VOYAGE OF A NATURALIST.\\r\\n\\r\\n\"\\'Stern all!\\' exclaimed the mate, as upon turning his head, he saw\\r\\nthe distended jaws of a large Sperm Whale close to the head of the\\r\\nboat, threatening it with instant destruction;--\\'Stern all, for your\\r\\nlives!\\'\" --WHARTON THE WHALE KILLER.\\r\\n\\r\\n\"So be cheery, my lads, let your hearts never fail,\\r\\nWhile the bold harpooneer is striking the whale!\" --NANTUCKET SONG.\\r\\n\\r\\n\"Oh, the rare old Whale, mid storm and gale\\r\\nIn his ocean home will be\\r\\nA giant in might, where might is right,\\r\\nAnd King of the boundless sea.\" --WHALE SONG.\\r\\n\\r\\n\\r\\n\\r\\nCHAPTER 1\\r\\n\\r\\nLoomings.\\r\\n\\r\\n\\r\\nCall me Ishmael.  Some years ago--never mind how long\\r\\nprecisely--having little or no money in my purse, and nothing\\r\\nparticular to interest me on shore, I thought I would sail about a\\r\\nlittle and see the watery part of the world.  It is a way I have of\\r\\ndriving off the spleen and regulating the circulation.  Whenever I\\r\\nfind myself growing grim about the mouth; whenever it is a damp,\\r\\ndrizzly November in my soul; whenever I find myself involuntarily\\r\\npausing before coffin warehouses, and bringing up the rear of every\\r\\nfu'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby[21000:22500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db237714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rful unbroken colt, with the mere appliance of a rope\r\n",
      "tied to the root of his tail.\" --A CHAPTER ON WHALING IN RIBS AND\r\n",
      "TRUCKS.\r\n",
      "\r\n",
      "\"On one occasion I saw two of these monsters (whales) probably male\r\n",
      "and female, slowly swimming, one after the other, within less than a\r\n",
      "stone's throw of the shore\" (Terra Del Fuego), \"over which the beech\r\n",
      "tree extended its branches.\" --DARWIN'S VOYAGE OF A NATURALIST.\r\n",
      "\r\n",
      "\"'Stern all!' exclaimed the mate, as upon turning his head, he saw\r\n",
      "the distended jaws of a large Sperm Whale close to the head of the\r\n",
      "boat, threatening it with instant destruction;--'Stern all, for your\r\n",
      "lives!'\" --WHARTON THE WHALE KILLER.\r\n",
      "\r\n",
      "\"So be cheery, my lads, let your hearts never fail,\r\n",
      "While the bold harpooneer is striking the whale!\" --NANTUCKET SONG.\r\n",
      "\r\n",
      "\"Oh, the rare old Whale, mid storm and gale\r\n",
      "In his ocean home will be\r\n",
      "A giant in might, where might is right,\r\n",
      "And King of the boundless sea.\" --WHALE SONG.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "CHAPTER 1\r\n",
      "\r\n",
      "Loomings.\r\n",
      "\r\n",
      "\r\n",
      "Call me Ishmael.  Some years ago--never mind how long\r\n",
      "precisely--having little or no money in my purse, and nothing\r\n",
      "particular to interest me on shore, I thought I would sail about a\r\n",
      "little and see the watery part of the world.  It is a way I have of\r\n",
      "driving off the spleen and regulating the circulation.  Whenever I\r\n",
      "find myself growing grim about the mouth; whenever it is a damp,\r\n",
      "drizzly November in my soul; whenever I find myself involuntarily\r\n",
      "pausing before coffin warehouses, and bringing up the rear of every\r\n",
      "fu\n"
     ]
    }
   ],
   "source": [
    "print(moby[21000:22500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86ebc853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21945"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby.find('CHAPTER 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102beb47",
   "metadata": {},
   "source": [
    "Lets try to match all chapters in the book. First, lets match the chapter sequence, they are similar to \"\\nCHAPTER 1\\r\\n\\r\\nLoomings.\\r\\n\". Check the novel [here](https://www.gutenberg.org/files/2701/2701-h/2701-h.htm#link2H_4_0002). Note that the full stop after the chapter is not in the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2efb8886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAPTER 1\\r\\n\\r\\nLoomings.',\n",
       " 'CHAPTER 5\\r\\n\\r\\nBreakfast.',\n",
       " 'CHAPTER 11\\r\\n\\r\\nNightgown.',\n",
       " 'CHAPTER 12\\r\\n\\r\\nBiographical.',\n",
       " 'CHAPTER 13\\r\\n\\r\\nWheelbarrow.',\n",
       " 'CHAPTER 14\\r\\n\\r\\nNantucket.',\n",
       " 'CHAPTER 15\\r\\n\\r\\nChowder.',\n",
       " 'CHAPTER 25\\r\\n\\r\\nPostscript.',\n",
       " 'CHAPTER 28\\r\\n\\r\\nAhab.',\n",
       " 'CHAPTER 32\\r\\n\\r\\nCetology.',\n",
       " 'CHAPTER 37\\r\\n\\r\\nSunset.',\n",
       " 'CHAPTER 38\\r\\n\\r\\nDusk.',\n",
       " 'CHAPTER 46\\r\\n\\r\\nSurmises.',\n",
       " 'CHAPTER 58\\r\\n\\r\\nBrit.',\n",
       " 'CHAPTER 59\\r\\n\\r\\nSquid.',\n",
       " 'CHAPTER 84\\r\\n\\r\\nPitchpoling.',\n",
       " 'CHAPTER 92\\r\\n\\r\\nAmbergris.',\n",
       " 'CHAPTER 121\\r\\n\\r\\nMidnight.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"CHAPTER\\s{1}\\d+\\s*\\w+\\.{1}\", moby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6f72b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CHAPTER 1', 'Loomings.'),\n",
       " ('CHAPTER 5', 'Breakfast.'),\n",
       " ('CHAPTER 11', 'Nightgown.'),\n",
       " ('CHAPTER 12', 'Biographical.'),\n",
       " ('CHAPTER 13', 'Wheelbarrow.'),\n",
       " ('CHAPTER 14', 'Nantucket.'),\n",
       " ('CHAPTER 15', 'Chowder.'),\n",
       " ('CHAPTER 25', 'Postscript.'),\n",
       " ('CHAPTER 28', 'Ahab.'),\n",
       " ('CHAPTER 32', 'Cetology.'),\n",
       " ('CHAPTER 37', 'Sunset.'),\n",
       " ('CHAPTER 38', 'Dusk.'),\n",
       " ('CHAPTER 46', 'Surmises.'),\n",
       " ('CHAPTER 58', 'Brit.'),\n",
       " ('CHAPTER 59', 'Squid.'),\n",
       " ('CHAPTER 84', 'Pitchpoling.'),\n",
       " ('CHAPTER 92', 'Ambergris.'),\n",
       " ('CHAPTER 121', 'Midnight.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"(CHAPTER\\s{1}\\d+)\\s*(\\w+\\.{1})\", moby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b04eaacd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CHAPTER 1', 'Loomings.'),\n",
       " ('CHAPTER 2', 'The Carpet-Bag.'),\n",
       " ('CHAPTER 3', 'The Spouter-Inn.'),\n",
       " ('CHAPTER 4', 'The Counterpane.'),\n",
       " ('CHAPTER 5', 'Breakfast.'),\n",
       " ('CHAPTER 6', 'The Street.'),\n",
       " ('CHAPTER 7', 'The Chapel.'),\n",
       " ('CHAPTER 8', 'The Pulpit.'),\n",
       " ('CHAPTER 9', 'The Sermon.'),\n",
       " ('CHAPTER 10', 'A Bosom Friend.'),\n",
       " ('CHAPTER 11', 'Nightgown.'),\n",
       " ('CHAPTER 12', 'Biographical.'),\n",
       " ('CHAPTER 13', 'Wheelbarrow.'),\n",
       " ('CHAPTER 14', 'Nantucket.'),\n",
       " ('CHAPTER 15', 'Chowder.'),\n",
       " ('CHAPTER 16', 'The Ship.'),\n",
       " ('CHAPTER 17', 'The Ramadan.'),\n",
       " ('CHAPTER 18', 'His Mark.'),\n",
       " ('CHAPTER 19', 'The Prophet.'),\n",
       " ('CHAPTER 20', 'All Astir.'),\n",
       " ('CHAPTER 21', 'Going Aboard.'),\n",
       " ('CHAPTER 22', 'Merry Christmas.'),\n",
       " ('CHAPTER 23', 'The Lee Shore.'),\n",
       " ('CHAPTER 24', 'The Advocate.'),\n",
       " ('CHAPTER 25', 'Postscript.'),\n",
       " ('CHAPTER 26', 'Knights and Squires.'),\n",
       " ('CHAPTER 27', 'Knights and Squires.'),\n",
       " ('CHAPTER 28', 'Ahab.'),\n",
       " ('CHAPTER 29', 'Enter Ahab; to Him, Stubb.'),\n",
       " ('CHAPTER 30', 'The Pipe.'),\n",
       " ('CHAPTER 31', 'Queen Mab.'),\n",
       " ('CHAPTER 32', 'Cetology.'),\n",
       " ('CHAPTER 1', '. (HUZZA PORPOISE).'),\n",
       " ('CHAPTER 33', 'The Specksynder.'),\n",
       " ('CHAPTER 34', 'The Cabin-Table.'),\n",
       " ('CHAPTER 35', 'The Mast-Head.'),\n",
       " ('CHAPTER 36', 'The Quarter-Deck.'),\n",
       " ('CHAPTER 37', 'Sunset.'),\n",
       " ('CHAPTER 38', 'Dusk.'),\n",
       " ('CHAPTER 39', 'First Night Watch.'),\n",
       " ('CHAPTER 40', 'Midnight, Forecastle.'),\n",
       " ('CHAPTER 41', 'Moby Dick.'),\n",
       " ('CHAPTER 42', 'The Whiteness of The Whale.'),\n",
       " ('CHAPTER 44', 'The Chart.'),\n",
       " ('CHAPTER 45', 'The Affidavit.'),\n",
       " ('CHAPTER 46', 'Surmises.'),\n",
       " ('CHAPTER 47', 'The Mat-Maker.'),\n",
       " ('CHAPTER 48', 'The First Lowering.'),\n",
       " ('CHAPTER 49', 'The Hyena.'),\n",
       " ('CHAPTER 50', \"Ahab's Boat and Crew.  Fedallah.\"),\n",
       " ('CHAPTER 51', 'The Spirit-Spout.'),\n",
       " ('CHAPTER 52', 'The Albatross.'),\n",
       " ('CHAPTER 53', 'The Gam.'),\n",
       " ('CHAPTER 54', \"The Town-Ho's Story.\"),\n",
       " ('CHAPTER 55', 'Of the Monstrous Pictures of Whales.'),\n",
       " ('CHAPTER 58', 'Brit.'),\n",
       " ('CHAPTER 59', 'Squid.'),\n",
       " ('CHAPTER 60', 'The Line.'),\n",
       " ('CHAPTER 61', 'Stubb Kills a Whale.'),\n",
       " ('CHAPTER 62', 'The Dart.'),\n",
       " ('CHAPTER 63', 'The Crotch.'),\n",
       " ('CHAPTER 64', \"Stubb's Supper.\"),\n",
       " ('CHAPTER 65', 'The Whale as a Dish.'),\n",
       " ('CHAPTER 66', 'The Shark Massacre.'),\n",
       " ('CHAPTER 67', 'Cutting In.'),\n",
       " ('CHAPTER 68', 'The Blanket.'),\n",
       " ('CHAPTER 69', 'The Funeral.'),\n",
       " ('CHAPTER 70', 'The Sphynx.'),\n",
       " ('CHAPTER 71', \"The Jeroboam's Story.\"),\n",
       " ('CHAPTER 72', 'The Monkey-Rope.'),\n",
       " ('CHAPTER 73',\n",
       "  'Stubb and Flask Kill a Right Whale; and Then Have a Talk Over Him.'),\n",
       " ('CHAPTER 74', \"The Sperm Whale's Head--Contrasted View.\"),\n",
       " ('CHAPTER 75', \"The Right Whale's Head--Contrasted View.\"),\n",
       " ('CHAPTER 76', 'The Battering-Ram.'),\n",
       " ('CHAPTER 77', 'The Great Heidelburgh Tun.'),\n",
       " ('CHAPTER 78', 'Cistern and Buckets.'),\n",
       " ('CHAPTER 79', 'The Prairie.'),\n",
       " ('CHAPTER 80', 'The Nut.'),\n",
       " ('CHAPTER 81', 'The Pequod Meets The Virgin.'),\n",
       " ('CHAPTER 82', 'The Honour and Glory of Whaling.'),\n",
       " ('CHAPTER 83', 'Jonah Historically Regarded.'),\n",
       " ('CHAPTER 84', 'Pitchpoling.'),\n",
       " ('CHAPTER 85', 'The Fountain.'),\n",
       " ('CHAPTER 86', 'The Tail.'),\n",
       " ('CHAPTER 87', 'The Grand Armada.'),\n",
       " ('CHAPTER 88', 'Schools and Schoolmasters.'),\n",
       " ('CHAPTER 89', 'Fast-Fish and Loose-Fish.'),\n",
       " ('CHAPTER 90', 'Heads or Tails.'),\n",
       " ('CHAPTER 91', 'The Pequod Meets The Rose-Bud.'),\n",
       " ('CHAPTER 92', 'Ambergris.'),\n",
       " ('CHAPTER 93', 'The Castaway.'),\n",
       " ('CHAPTER 94', 'A Squeeze of the Hand.'),\n",
       " ('CHAPTER 95', 'The Cassock.'),\n",
       " ('CHAPTER 96', 'The Try-Works.'),\n",
       " ('CHAPTER 97', 'The Lamp.'),\n",
       " ('CHAPTER 98', 'Stowing Down and Clearing Up.'),\n",
       " ('CHAPTER 99', 'The Doubloon.'),\n",
       " ('CHAPTER 100', 'Leg and Arm.'),\n",
       " ('CHAPTER 101', 'The Decanter.'),\n",
       " ('CHAPTER 102', 'A Bower in the Arsacides.'),\n",
       " ('CHAPTER 103', \"Measurement of The Whale's Skeleton.\"),\n",
       " ('CHAPTER 104', 'The Fossil Whale.'),\n",
       " ('CHAPTER 106', \"Ahab's Leg.\"),\n",
       " ('CHAPTER 107', 'The Carpenter.'),\n",
       " ('CHAPTER 108', 'Ahab and the Carpenter.'),\n",
       " ('CHAPTER 109', 'Ahab and Starbuck in the Cabin.'),\n",
       " ('CHAPTER 110', 'Queequeg in His Coffin.'),\n",
       " ('CHAPTER 111', 'The Pacific.'),\n",
       " ('CHAPTER 112', 'The Blacksmith.'),\n",
       " ('CHAPTER 113', 'The Forge.'),\n",
       " ('CHAPTER 114', 'The Gilder.'),\n",
       " ('CHAPTER 115', 'The Pequod Meets The Bachelor.'),\n",
       " ('CHAPTER 116', 'The Dying Whale.'),\n",
       " ('CHAPTER 117', 'The Whale Watch.'),\n",
       " ('CHAPTER 118', 'The Quadrant.'),\n",
       " ('CHAPTER 119', 'The Candles.'),\n",
       " ('CHAPTER 120', 'The Deck Towards the End of the First Night Watch.'),\n",
       " ('CHAPTER 121', 'Midnight.--The Forecastle Bulwarks.'),\n",
       " ('CHAPTER 122', 'Midnight Aloft.--Thunder and Lightning.'),\n",
       " ('CHAPTER 123', 'The Musket.'),\n",
       " ('CHAPTER 124', 'The Needle.'),\n",
       " ('CHAPTER 125', 'The Log and Line.'),\n",
       " ('CHAPTER 126', 'The Life-Buoy.'),\n",
       " ('CHAPTER 127', 'The Deck.'),\n",
       " ('CHAPTER 128', 'The Pequod Meets The Rachel.'),\n",
       " ('CHAPTER 129', 'The Cabin.'),\n",
       " ('CHAPTER 130', 'The Hat.'),\n",
       " ('CHAPTER 131', 'The Pequod Meets The Delight.'),\n",
       " ('CHAPTER 132', 'The Symphony.'),\n",
       " ('CHAPTER 133', 'The Chase--First Day.'),\n",
       " ('CHAPTER 134', 'The Chase--Second Day.'),\n",
       " ('CHAPTER 135', 'The Chase.--Third Day.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"(CHAPTER\\s{1}\\d+)\\s*(.+\\.{1})\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1edf6f",
   "metadata": {},
   "source": [
    "See chapter 43. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9840e013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CHAPTER 1', 'Loomings.'),\n",
       " ('CHAPTER 2', 'The Carpet-Bag.'),\n",
       " ('CHAPTER 3', 'The Spouter-Inn.'),\n",
       " ('CHAPTER 4', 'The Counterpane.'),\n",
       " ('CHAPTER 5', 'Breakfast.'),\n",
       " ('CHAPTER 6', 'The Street.'),\n",
       " ('CHAPTER 7', 'The Chapel.'),\n",
       " ('CHAPTER 8', 'The Pulpit.'),\n",
       " ('CHAPTER 9', 'The Sermon.'),\n",
       " ('CHAPTER 10', 'A Bosom Friend.'),\n",
       " ('CHAPTER 11', 'Nightgown.'),\n",
       " ('CHAPTER 12', 'Biographical.'),\n",
       " ('CHAPTER 13', 'Wheelbarrow.'),\n",
       " ('CHAPTER 14', 'Nantucket.'),\n",
       " ('CHAPTER 15', 'Chowder.'),\n",
       " ('CHAPTER 16', 'The Ship.'),\n",
       " ('CHAPTER 17', 'The Ramadan.'),\n",
       " ('CHAPTER 18', 'His Mark.'),\n",
       " ('CHAPTER 19', 'The Prophet.'),\n",
       " ('CHAPTER 20', 'All Astir.'),\n",
       " ('CHAPTER 21', 'Going Aboard.'),\n",
       " ('CHAPTER 22', 'Merry Christmas.'),\n",
       " ('CHAPTER 23', 'The Lee Shore.'),\n",
       " ('CHAPTER 24', 'The Advocate.'),\n",
       " ('CHAPTER 25', 'Postscript.'),\n",
       " ('CHAPTER 26', 'Knights and Squires.'),\n",
       " ('CHAPTER 27', 'Knights and Squires.'),\n",
       " ('CHAPTER 28', 'Ahab.'),\n",
       " ('CHAPTER 29', 'Enter Ahab; to Him, Stubb.'),\n",
       " ('CHAPTER 30', 'The Pipe.'),\n",
       " ('CHAPTER 31', 'Queen Mab.'),\n",
       " ('CHAPTER 32', 'Cetology.'),\n",
       " ('CHAPTER 1', '. (HUZZA PORPOISE).'),\n",
       " ('CHAPTER 33', 'The Specksynder.'),\n",
       " ('CHAPTER 34', 'The Cabin-Table.'),\n",
       " ('CHAPTER 35', 'The Mast-Head.'),\n",
       " ('CHAPTER 36', 'The Quarter-Deck.'),\n",
       " ('CHAPTER 37', 'Sunset.'),\n",
       " ('CHAPTER 38', 'Dusk.'),\n",
       " ('CHAPTER 39', 'First Night Watch.'),\n",
       " ('CHAPTER 40', 'Midnight, Forecastle.'),\n",
       " ('CHAPTER 41', 'Moby Dick.'),\n",
       " ('CHAPTER 42', 'The Whiteness of The Whale.'),\n",
       " ('CHAPTER 43', 'Hark!'),\n",
       " ('CHAPTER 44', 'The Chart.'),\n",
       " ('CHAPTER 45', 'The Affidavit.'),\n",
       " ('CHAPTER 46', 'Surmises.'),\n",
       " ('CHAPTER 47', 'The Mat-Maker.'),\n",
       " ('CHAPTER 48', 'The First Lowering.'),\n",
       " ('CHAPTER 49', 'The Hyena.'),\n",
       " ('CHAPTER 50', \"Ahab's Boat and Crew.  Fedallah.\"),\n",
       " ('CHAPTER 51', 'The Spirit-Spout.'),\n",
       " ('CHAPTER 52', 'The Albatross.'),\n",
       " ('CHAPTER 53', 'The Gam.'),\n",
       " ('CHAPTER 54', \"The Town-Ho's Story.\"),\n",
       " ('CHAPTER 55', 'Of the Monstrous Pictures of Whales.'),\n",
       " ('CHAPTER 58', 'Brit.'),\n",
       " ('CHAPTER 59', 'Squid.'),\n",
       " ('CHAPTER 60', 'The Line.'),\n",
       " ('CHAPTER 61', 'Stubb Kills a Whale.'),\n",
       " ('CHAPTER 62', 'The Dart.'),\n",
       " ('CHAPTER 63', 'The Crotch.'),\n",
       " ('CHAPTER 64', \"Stubb's Supper.\"),\n",
       " ('CHAPTER 65', 'The Whale as a Dish.'),\n",
       " ('CHAPTER 66', 'The Shark Massacre.'),\n",
       " ('CHAPTER 67', 'Cutting In.'),\n",
       " ('CHAPTER 68', 'The Blanket.'),\n",
       " ('CHAPTER 69', 'The Funeral.'),\n",
       " ('CHAPTER 70', 'The Sphynx.'),\n",
       " ('CHAPTER 71', \"The Jeroboam's Story.\"),\n",
       " ('CHAPTER 72', 'The Monkey-Rope.'),\n",
       " ('CHAPTER 73',\n",
       "  'Stubb and Flask Kill a Right Whale; and Then Have a Talk Over Him.'),\n",
       " ('CHAPTER 74', \"The Sperm Whale's Head--Contrasted View.\"),\n",
       " ('CHAPTER 75', \"The Right Whale's Head--Contrasted View.\"),\n",
       " ('CHAPTER 76', 'The Battering-Ram.'),\n",
       " ('CHAPTER 77', 'The Great Heidelburgh Tun.'),\n",
       " ('CHAPTER 78', 'Cistern and Buckets.'),\n",
       " ('CHAPTER 79', 'The Prairie.'),\n",
       " ('CHAPTER 80', 'The Nut.'),\n",
       " ('CHAPTER 81', 'The Pequod Meets The Virgin.'),\n",
       " ('CHAPTER 82', 'The Honour and Glory of Whaling.'),\n",
       " ('CHAPTER 83', 'Jonah Historically Regarded.'),\n",
       " ('CHAPTER 84', 'Pitchpoling.'),\n",
       " ('CHAPTER 85', 'The Fountain.'),\n",
       " ('CHAPTER 86', 'The Tail.'),\n",
       " ('CHAPTER 87', 'The Grand Armada.'),\n",
       " ('CHAPTER 88', 'Schools and Schoolmasters.'),\n",
       " ('CHAPTER 89', 'Fast-Fish and Loose-Fish.'),\n",
       " ('CHAPTER 90', 'Heads or Tails.'),\n",
       " ('CHAPTER 91', 'The Pequod Meets The Rose-Bud.'),\n",
       " ('CHAPTER 92', 'Ambergris.'),\n",
       " ('CHAPTER 93', 'The Castaway.'),\n",
       " ('CHAPTER 94', 'A Squeeze of the Hand.'),\n",
       " ('CHAPTER 95', 'The Cassock.'),\n",
       " ('CHAPTER 96', 'The Try-Works.'),\n",
       " ('CHAPTER 97', 'The Lamp.'),\n",
       " ('CHAPTER 98', 'Stowing Down and Clearing Up.'),\n",
       " ('CHAPTER 99', 'The Doubloon.'),\n",
       " ('CHAPTER 100', 'Leg and Arm.'),\n",
       " ('CHAPTER 101', 'The Decanter.'),\n",
       " ('CHAPTER 102', 'A Bower in the Arsacides.'),\n",
       " ('CHAPTER 103', \"Measurement of The Whale's Skeleton.\"),\n",
       " ('CHAPTER 104', 'The Fossil Whale.'),\n",
       " ('CHAPTER 105', \"Does the Whale's Magnitude Diminish?--Will He Perish?\"),\n",
       " ('CHAPTER 106', \"Ahab's Leg.\"),\n",
       " ('CHAPTER 107', 'The Carpenter.'),\n",
       " ('CHAPTER 108', 'Ahab and the Carpenter.'),\n",
       " ('CHAPTER 109', 'Ahab and Starbuck in the Cabin.'),\n",
       " ('CHAPTER 110', 'Queequeg in His Coffin.'),\n",
       " ('CHAPTER 111', 'The Pacific.'),\n",
       " ('CHAPTER 112', 'The Blacksmith.'),\n",
       " ('CHAPTER 113', 'The Forge.'),\n",
       " ('CHAPTER 114', 'The Gilder.'),\n",
       " ('CHAPTER 115', 'The Pequod Meets The Bachelor.'),\n",
       " ('CHAPTER 116', 'The Dying Whale.'),\n",
       " ('CHAPTER 117', 'The Whale Watch.'),\n",
       " ('CHAPTER 118', 'The Quadrant.'),\n",
       " ('CHAPTER 119', 'The Candles.'),\n",
       " ('CHAPTER 120', 'The Deck Towards the End of the First Night Watch.'),\n",
       " ('CHAPTER 121', 'Midnight.--The Forecastle Bulwarks.'),\n",
       " ('CHAPTER 122', 'Midnight Aloft.--Thunder and Lightning.'),\n",
       " ('CHAPTER 123', 'The Musket.'),\n",
       " ('CHAPTER 124', 'The Needle.'),\n",
       " ('CHAPTER 125', 'The Log and Line.'),\n",
       " ('CHAPTER 126', 'The Life-Buoy.'),\n",
       " ('CHAPTER 127', 'The Deck.'),\n",
       " ('CHAPTER 128', 'The Pequod Meets The Rachel.'),\n",
       " ('CHAPTER 129', 'The Cabin.'),\n",
       " ('CHAPTER 130', 'The Hat.'),\n",
       " ('CHAPTER 131', 'The Pequod Meets The Delight.'),\n",
       " ('CHAPTER 132', 'The Symphony.'),\n",
       " ('CHAPTER 133', 'The Chase--First Day.'),\n",
       " ('CHAPTER 134', 'The Chase--Second Day.'),\n",
       " ('CHAPTER 135', 'The Chase.--Third Day.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"(CHAPTER\\s{1}\\d+)\\s*(.+[\\.{1}|!{1}|\\?{1}])\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b9ccd",
   "metadata": {},
   "source": [
    "Chapter 1 reappeared! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"(?<!,\\s)(CHAPTER\\s{1}\\d+)\\s*(.+[\\.{1}|!{1}|\\?{1}])\", moby) # do not capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f84f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1a670eb",
   "metadata": {},
   "source": [
    "Lets use a negatve lookbehind! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"(?<!,\\s*)(CHAPTER\\s{1}\\d+)\\s*(.+[\\.{1}|!{1}])\", moby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54df124",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"(?<!,\\s{1})(CHAPTER\\s{1}\\d+)\\s*(.+[\\.{1}|!{1}])\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294deef",
   "metadata": {},
   "source": [
    "Lets find the unmatched chapters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chapters = [i for i in range(1,135)]\n",
    "matched_chapters = [int(i) for i in \n",
    "                    re.findall(r\"(?<!,\\s{1})(?:CHAPTER\\s{1})(\\d+)(?:\\s*.+[\\.{1}|!{1}])\", moby)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a2547",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in all_chapters if not i in matched_chapters ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1137c3bf",
   "metadata": {},
   "source": [
    "There is another new line! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"(?<!,\\s)(CHAPTER\\s{1}\\d+)\\s*(.+\\s*.*[\\.{1}|!{1}])\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366c53c",
   "metadata": {},
   "source": [
    "Lets be lazy! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac815fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"(?<!,\\s{1})(CHAPTER\\s{1}\\d+)\\s*(.+?\\s*.*[\\.{1}|!{1}|\\?{1}])\", moby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"(?<!,\\s{1})(CHAPTER\\s{1}\\d+|Epilogue|EXTRACTS)\\s*(.+?\\s*.*[\\.{1}|!{1}|\\?{1}])\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485ba69a",
   "metadata": {},
   "source": [
    "Lets use a positive lookahead `(?=...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94fa3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"(?<!,\\s{1})(CHAPTER\\s{1}\\d+|Epilogue|EXTRACTS(?=\\s*\\())\\s*(.+?\\s*.*[\\.{1}|!{1}])\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e23be5",
   "metadata": {},
   "source": [
    "To match `\"ETYMOLOGY.\"`, we have to account for parenthesis. (Note the extra `\\.*`!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"(?<!,\\s{1})(ETYMOLOGY|CHAPTER\\s{1}\\d+|Epilogue|EXTRACTS(?=\\s*\\())\\.*\\s*(.+?\\s*.*[\\.{1}|!{1}|\\){1}|\\?{1}])\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5e3cd",
   "metadata": {},
   "source": [
    "Perfect! But what if we want to match the chapters that follow after his matched string? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r\"((?<!,\\s{1})(?:ETYMOLOGY|CHAPTER\\s{1}\\d+|Epilogue|EXTRACTS(?=\\s*\\())(?:\\.*\\s*).+?\\s*.*[\\.{1}|!{1}|\\){1}|\\?{1}])\", moby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64843203",
   "metadata": {},
   "source": [
    "Check the [docs](https://docs.python.org/3/library/re.html#re.split). Remove the capturing group when splitting! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = re.split(r\"(?<!,\\s{1})(?:ETYMOLOGY|CHAPTER\\s{1}\\d+|Epilogue|EXTRACTS(?=\\s*\\())(?:\\.*\\s*).+?\\s*.*[\\.{1}|!{1}|\\){1}|\\?{1}]\", moby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbeb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c146dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = [re.sub(r\"\\s+\", \" \", chapter) for chapter in chapters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a2acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter = chapters[3]\n",
    "chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f294cd7",
   "metadata": {},
   "source": [
    "Back to tokenizing! Tokenizing natural languages is a difficult problem. Some tokenizers work better for certain kinds of documents than others.\n",
    "\n",
    "Before building your own tokenizer, try the tokenizers included with __nltk__, in the `nltk.tokenize` submodule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f94d8",
   "metadata": {},
   "source": [
    "### Standardizing Text\n",
    "\n",
    "We standardize numerical data in order to make fair comparisons, comparisons that are not influenced by the location and scale of the data. Similarly, you can standardize text (tokens) to make sure comparisons are fair and accurate.\n",
    "\n",
    "For example, `\"Cat\"` and `\"cat\"` are the same word even though they're different tokens. Converting all characters to lowercase is one way to standardize a document.\n",
    "\n",
    "Some common standardization techniques for text are:\n",
    "\n",
    "* Lowercasing\n",
    "* Stemming: Use patterns to remove prefixes and suffixes from words.\n",
    "* Lemmatiziation: Look up each token in a dictionary and replace it with a root word. Similar to stemming, but more accurate.\n",
    "* Stopword Removal: Remove tokens that don't contribute meaning. For example, \"the\" is meaningless on its own.\n",
    "* Identifying Outliers: Identify and possibly remove non-standard \"words\" like numbers, mispellings, code, etc...\n",
    "\n",
    "How and whether you should standardize a document or corpus depends on what kind of analysis you want to do. There is no formula; you must think carefully and experiment to determine which standardization techniques work best for your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92498eb3",
   "metadata": {},
   "source": [
    "#### Lowercasing\n",
    "\n",
    "You can use Python's string methods for simple text transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc71198",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter.lower()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f02f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter.upper()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b650aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = re.findall(r\"\\w+\", chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb972c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = [w.lower() for w in words] # lower and upper\n",
    "lower[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85ffc3",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "\n",
    "_Stemming_ runs an algorithm on each token to remove affixes (prefixes and suffixes). The result is called a _stem_.\n",
    "\n",
    "Stemming is useful if you want to ignore affixes.\n",
    "\n",
    "For example, most English verbs use suffixes to mark the tense. We write \"They fish\" (present) and \"They fished\" (past). Without any standardization, the tokens \"fish\" and \"fished\" would be treated as separate words. Stemming converts both tokens to the common stem \"fish\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5fb85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[nltk.PorterStemmer().stem(w) for w in words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78092c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk.PorterStemmer().stem(\"whales\"))\n",
    "print(nltk.PorterStemmer().stem(\"whaling\"))\n",
    "print(nltk.PorterStemmer().stem(\"whalebone\"))\n",
    "print(nltk.PorterStemmer().stem(\"narwhales\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db74f0e6",
   "metadata": {},
   "source": [
    "Stemmers use a sequence of rules to determine the stem for each token, but natural languages are full of special cases and exceptions. So as you can see in the example above, some stems are not words , and sometimes tokens that seem like they should have the same stem don't.\n",
    "\n",
    "Several different stemmers are provided in the `nltk.stem` submodule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc949c",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "\n",
    "_Lemmatization_ looks up each token in a dictionary to find a root word, or _lemma_.\n",
    "\n",
    "Lemmatization serves the same purpose as stemming. Lemmatization is more accurate, but requires a dictionary and usually takes longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e0b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.WordNetLemmatizer().lemmatize(\"whales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.WordNetLemmatizer().lemmatize(\"whaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17885c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.WordNetLemmatizer().lemmatize(\"whaling\", \"v\") #this is a verb - it should be lemmatized to 'whale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc390be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.WordNetLemmatizer().lemmatize(\"whalebone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28eced",
   "metadata": {},
   "source": [
    "The WordNet lemmatizer requires part of speech information in order to lemmatize words. You can get approximate part of speech information with __nltk__'s `pos_tag()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0997f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag([\"whaling\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae88f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag([\"whale\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abdce05",
   "metadata": {},
   "source": [
    "NLTK POS Tags are [Brown POS tags][brown]\n",
    "\n",
    "[brown]: https://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a6f9d",
   "metadata": {},
   "source": [
    "#### Foreign language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = SnowballStemmer('french')\n",
    "\n",
    "sent = \"En mathmatiques, une fonction cdlg (continue  droite, limite  gauche) est ...\"\n",
    "nltk.word_tokenize(sent)\n",
    "\n",
    "nltk.pos_tag([fr.stem(word) for word in nltk.word_tokenize(sent)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be58789",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_tags = nltk.pos_tag(words)\n",
    "moby_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd0c9f",
   "metadata": {},
   "source": [
    "The `nltk.stem` submodule also provides several different lemmatizers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62368977",
   "metadata": {},
   "source": [
    "### Stopword Removal\n",
    "\n",
    "_Stopwords_ are words that appear frequently but don't add meaning.\n",
    "\n",
    "In English, \"the\", \"a\", and \"at\" are examples. However, exactly which words are stopwords depends on your analysis. Words that are meaningless in one analysis might be very important in others.\n",
    "\n",
    "You can filter out stopwords with a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f994bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"the\", \"a\", \"and\", \"or\", \"in\", \"by\"]\n",
    "[w for w in words if w not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f8ef17",
   "metadata": {},
   "source": [
    "__nltk__ also provides a stopwords corpus that contains common stopwords for several languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "[w for w in words if w not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c164b",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "- Learn Regular Expressions to rule natural languages \n",
    "- Processing depends on use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2b12ec50b0a525a62abe739e766b0c808eccd181e3f804cedbbca00f4d5b392"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
