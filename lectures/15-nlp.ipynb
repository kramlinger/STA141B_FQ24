{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff704263",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STA 141B Data & Web Technologies for Data Analysis\n",
    "\n",
    "### Lecture 15, 11/19/24, Natural language processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1ee6c",
   "metadata": {},
   "source": [
    "### Last week's topics\n",
    "\n",
    "- Tokenizing\n",
    "- Tagging\n",
    "- Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb3382",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Today's topics\n",
    "- Natural Language Processing\n",
    "    - Naive Bayes\n",
    "    - ROC space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18193e33",
   "metadata": {},
   "source": [
    "The goal of today is to answer the following questions:\n",
    "1. How can we identify particular features of language data that are salient for classifying it?\n",
    "2. How can we construct models of language that can be used to perform language processing tasks automatically?\n",
    "3. What can we learn about language from these models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57094326",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes Classifier\n",
    "\n",
    "We aim to find the probability for a label. The following algorithm first uses the Bayes rule to express $P(label|features)$ in terms of $P(label)$ and $P(features|label)$, where the latter are approximated from the test data set: \n",
    "$$\n",
    "P(label|features) = \\frac{P(features|label)P(label)}{P(features)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9196ce1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As usual for discrete data, the probability in the denominator is not computed directly. Instead, the numerator is normalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845f6db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, we make the 'naive' assumption that all features are independent, given the label:\n",
    "$$\n",
    "P(label|features) \\propto P(label) P(feature\\ 1|label) \\dots P(feature\\ n|label)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce03e5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To exemplify, we will consider a simple case first, a single feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55283a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f6eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "         [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4cecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "names[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_features(\"Trinity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491464e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [({'feature': gender_features(n)}, g) for n, g in names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb11972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c175c",
   "metadata": {},
   "source": [
    "First, lets estimate $P(label)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91216363",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_label = np.mean([True if g[1] == 'male' else False for g in train_set])\n",
    "print(P_label)\n",
    "print(np.mean([True if g[1] == 'female' else False for g in train_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(feature, label): \n",
    "    return np.mean([True if f['feature'] == feature else False for f, y in train_set if y == label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4cf546",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood('a', 'female')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee09fa5",
   "metadata": {},
   "source": [
    "To compute the posterior, lets establish how many features there are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f50f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {f['feature'] for f, g in train_set}\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52329621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27584663",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_male = {f: P_label * likelihood(f, 'male') for f in features}\n",
    "posterior_female = {f: (1 - P_label) * likelihood(f, 'female') for f in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a97b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = {k: posterior_male.get(k, 0) + posterior_female.get(k, 0) for k in set(posterior_female) & set(posterior_male)}\n",
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976edfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_male = {f: P_label * likelihood(f, 'male') / normalization.get(f, 0) for f in features}\n",
    "posterior_female = {f: (1 - P_label) * likelihood(f, 'female') / normalization.get(f, 0) for f in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posterior_male.get('k')) # prob of label given feature\n",
    "print(posterior_female.get('k'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee050d",
   "metadata": {},
   "source": [
    "Our classifier is implemented. How well does it do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_female.get(gender_features('Esther')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01993bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a7783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.prob_classify({'feature': gender_features('Esther')}).prob('female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.prob_classify({'feature': gender_features('Esther')}).samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_features('Esther')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e998330",
   "metadata": {},
   "source": [
    "Lets classify [Moby Dick](https://www.gutenberg.org/files/2701/2701-h/2701-h.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cedd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "moby = nltk.corpus.gutenberg.raw(\"melville-moby_dick.txt\")\n",
    "pattern = r\"(?<!,\\s{1})(?:ETYMOLOGY|CHAPTER\\s{1}\\d+|Epilogue|EXTRACTS(?=\\s*\\())(?:\\.*\\s*).+?\\s*.*[\\.{1}|!{1}|\\?{1}|\\){1}]\"\n",
    "corpus = re.split(pattern, moby)\n",
    "corpus.pop(0)\n",
    "corpus = [re.sub(r\"\\s+\", \" \", document).lower() for document in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0c934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a68b6df",
   "metadata": {},
   "source": [
    "From [here](https://digitalcommons.cwu.edu/cgi/viewcontent.cgi?article=1430&context=etd#:~:text=In%20Chapters%201%2D8%2C%2010,role%20of%20%22I%22%20narrator.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3953fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cetological = [0, 1, 26, 27, 46, 55, 57, 58, 59, 60, 61, 63, 64, 68, 75, 76, 77, 78, 80, 81, 85, 86, 87, 89, 90, 91, 93, 96, 97, 98, 102, 103, 104, 105, 106, 107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = [i not in cetological for i in range(138)]\n",
    "story = [i for i in map(lambda x: 'story' if x else 'ceto', story)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(document): \n",
    "    words = re.findall('\\w+', document)\n",
    "    words = [w[0] for a, w in nltk.pos_tag(words) if w[0] in ['N', 'V', 'J', 'R', 'P']]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(tokenizer = tokenizer) \n",
    "tfidf = vec.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412094d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_as_dict(i): \n",
    "    row = tfidf[i,:].todense().tolist()[0]\n",
    "    names = vec.get_feature_names_out()\n",
    "    return {n: r for r, n in zip(row, names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_row_as_dict(130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5008fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(get_row_as_dict(i), story[i]) for i, _ in enumerate(corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11872ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(featuresets)\n",
    "train_set, test_set = featuresets[:90], featuresets[90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5545e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([True for i in story if i==\"story\"]) / len(story) #benchmark accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = fn = tp = tn = 0\n",
    "for test in test_set: \n",
    "    classification = classifier.classify(test[0])\n",
    "    truth = test[1]\n",
    "    if classification == truth and truth == 'story': tp += 1\n",
    "    if classification == truth and truth != 'story': tn += 1\n",
    "    if classification != truth and truth == 'story': fp += 1\n",
    "    if classification != truth and truth != 'story': fn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e084a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confusion = pd.DataFrame([[tp, fn], [fp, tn]], \n",
    "                         columns = ['true story', 'true ceto'], index = ['class story', 'class ceto'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb57c29",
   "metadata": {},
   "source": [
    "We assign a chapter to be either cetological or storyline depending on the respective probability exceeding $0.5$. But this is an arbitrary decision rule.\n",
    "\n",
    "Instead, one should consider choosing cetological chapters based on different thresholds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3659320",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "| Estimated \\ True      | Success        | Failure       |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Success        | $n_{1|1}$, true positive   | $n_{1|2}$, false positive |\n",
    "| Failure       | $n_{2|1}$, false negative  | $n_{2|2}$, true negative  |\n",
    "\n",
    "From the values of the confusion matrix the following measures can be calculated for the evaluation of the classification model: \n",
    " - true positive rate (TPR / sensitivity): $\\frac{n_{1|1}}{n_{1|1} + n_{2|1}}$\n",
    " - false negative rate: $\\frac{n_{2|1}}{n_{1|1} + n_{2|1}}$\n",
    " - false positive rate (FPR): $\\frac{n_{1|2}}{n_{1|2} + n_{2|2}}$\n",
    " - true negative rate (specificity): $\\frac{n_{2|2}}{n_{1|2} + n_{2|2}}$\n",
    " - positive prediction rate (precision): $\\frac{n_{1|1}}{n_{1|1} + n_{1|2}}$\n",
    " - false detection rate: $\\frac{n_{1|2}}{n_{1|1} + n_{1|2}}$\n",
    " - negative prediction rate (separability): $\\frac{n_{2|2}}{n_{2|1} + n_{2|2}}$\n",
    " - misclassification rate: $\\frac{n_{2|1}}{n_{2|1} + n_{2|2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b420e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion.iloc[0, 0] / (confusion.iloc[0, 0] + confusion.iloc[1, 0]) #TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f731a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion.iloc[0, 1] / (confusion.iloc[0, 1] + confusion.iloc[1, 1]) #FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ecf4f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ROC Plots\n",
    "\n",
    "A ROC (receiver operating characteristics) plot plots the FPR on the x-axis onto the TPR on the y-axis. \n",
    "\n",
    "The point $(0,0)$ means that a model never classifies a success: $n_{1|1} = n_{1|2} = 0$. \n",
    "This way we avoid false positive errors, at the cost of never having any true positive classifications either. \n",
    "Point $(0,1)$ corresponds to a perfect classification $n_{2|1} = n_{1|2} = 0$. \n",
    "\n",
    "A point is *better in the ROC space* than another point, if its TPR is larger and its FPR smaller than the TPR and FPR of the other point. \n",
    "\n",
    "A point below the bisector $x = y$ corresponds to a point which is worse than a uniformly random classification. The bisector corresponds to a uniform random classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b350b077",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use classification methods that return decision for the class (e.g., success or failure), or methods that return a probability that the observation belongs to a certain class (e.g., $\\pi$). For the latter, we have to set a threshold $\\tau\\in[0,1]$, to retrieve a true classification. \n",
    "Changing the threshold, will change the TPR and FPR. This leads to a *ROC curve*. \n",
    "\n",
    "Let $\\hat\\pi_i\\in[0,1]$ be the estimate for probability of the i-th observation is a success. \n",
    "Define $f_j$ to be the probability mass function of a random variable $p_j$, $j = 0,1$, where the realizations of $p_j$ are the values $\\hat\\pi_i$ that correspond to $y_i = j$. Now we can interpret the FPR and TRP as functions of the threshold $\\tau$. \n",
    "\n",
    "$$\n",
    "TPR(\\tau) = \\int_\\tau^\\infty f_1(x) dx\\qquad FPR(\\tau) = \\int_\\tau^{\\infty} f_0(x) dx \n",
    "$$\n",
    "\n",
    "This gives the ROC curve $\\tau\\rightarrow(FPR(\\tau), TPR(\\tau))$ as a function of $\\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8cb48",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def TPR(tau, classifier, featuresets, target = 'story'): \n",
    "    pi = np.array([classifier.prob_classify(chapter[0]).prob(target) for chapter in featuresets if chapter[1] == 'story'])\n",
    "    norm = len([True for chapter in featuresets if chapter[1] == 'story'])\n",
    "    tpr = [sum(pi >= t) / norm for t in tau]\n",
    "    return tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624f025",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "TPR([0], classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cddf1f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def FPR(tau, classifier, featuresets, target = 'story'): \n",
    "    pi = np.array([classifier.prob_classify(chapter[0]).prob(target) for chapter in featuresets if chapter[1] != 'story'])\n",
    "    norm = len([True for chapter in featuresets if chapter[1] != 'story'])\n",
    "    fpr = [sum(pi >= t) / norm for t in tau]\n",
    "    return fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ef88b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "FPR([0], classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ce7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'tau': [0, 0.1, 0.2, 0.5, 0.9, 1],\n",
    "    'tpr': TPR([0, 0.1, 0.2, 0.5, 0.9, 1], classifier, test_set),\n",
    "    'fpr': FPR([0, 0.1, 0.2, 0.5, 0.9, 1], classifier, test_set)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fab065",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(df, x=\"fpr\", y=\"tpr\", text = 'tau')\n",
    "fig.update_layout(yaxis_range=[-0.1,1.1], \n",
    "                  xaxis_range=[-0.1,1.1])\n",
    "fig.update_traces(textposition=\"bottom right\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32960cb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To compare different classification methods, we can use the area under the curve (AUC). \n",
    "One can show that the AUC $= P(p_0 > p_1)$. \n",
    "The larger the AUC, the better the method in classifying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d492c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[::-1]\n",
    "np.trapz(df['tpr'], df['fpr']) # AUC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2b12ec50b0a525a62abe739e766b0c808eccd181e3f804cedbbca00f4d5b392"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
